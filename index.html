<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Musings</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Musings</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#news---goat-in-current"
id="toc-news---goat-in-current">NEWS - Goat in Current</a></li>
<li><a href="#news---a-virgin-woman" id="toc-news---a-virgin-woman">NEWS
- A Virgin Woman</a></li>
<li><a href="#check-if-nvidia-driver-is-installed"
id="toc-check-if-nvidia-driver-is-installed">Check if nvidia driver is
installed</a></li>
<li><a href="#install-cuda-toolkit-11.3-upgrade-1-for-ubuntu-20.04-lts"
id="toc-install-cuda-toolkit-11.3-upgrade-1-for-ubuntu-20.04-lts">Install
CUDA toolkit 11.3 Upgrade 1 for Ubuntu 20.04 LTS</a></li>
<li><a href="#array-away" id="toc-array-away">Array Away</a>
<ul>
<li><a href="#matching-pairs" id="toc-matching-pairs">Matching
Pairs</a></li>
<li><a href="#sorting-squared-array"
id="toc-sorting-squared-array">Sorting Squared Array</a></li>
<li><a href="#tournament-winner" id="toc-tournament-winner">Tournament
Winner</a></li>
</ul></li>
</ul>
</nav>
<!-- SPDX-License-Identifier: zlib-acknowledgement -->
<h1 id="news---goat-in-current">NEWS - Goat in Current</h1>
<p>Time-of-flight sensors can be used to detect water levels</p>
<p>EMV (europay, mastercard and visa) secure payment technology embedded
in credit card chip</p>
<p>Waited till USB-C becoming standard to introduce reversible USB-A
(achieved with movable plastic divider and duplicated pins) Intel
thunderbolt faster than USB-C, yet ports still look very similar</p>
<p>AI in sensors used to alter configuration to optimise power
consumption AI generated voice, text. Disney can now alter age AI
parsing of voice (natural language processing) In summary, generative AI
everywhere. In fact, with ChatGPT being able to explain technical
concepts, birth of AGI (artificial general intelligence) Perhaps this
could be used as a sort of offline search engine. In fact, ChatGPT
generate prompt for DALLE Whilst ChatGPT solves problems considering
computers as generalised machines, it seems eventually it will get
there. So, embedded probably the last the be tackled due to unique
systems</p>
<p>Genetic engineering in flora seems more appetising,
e.g. drought-resistance wheat, air purifing plants</p>
<p>Batcat tool is cat with syntax highlighting</p>
<p>Skeptical of announcements made by budget-starved laboratories
(e.g. universities) about breakthroughs for technologies decades away,
e.g. fusion There are often caveats and furthermore, commerciality is
most likely decades away</p>
<p>Seems that bipartisan government action required to fix rats nest of
drivers in modern OSs in a similar vein to EU enforcing anti-competitive
laws on Apple to allow third-party apps, USB-C etc.</p>
<p>Have to be careful not to engage in technological contempt culture,
e.g. language wars. As technology changes rapidly, address changes with
temperance</p>
<!-- SPDX-License-Identifier: zlib-acknowledgement -->
<h1 id="news---a-virgin-woman">NEWS - A Virgin Woman</h1>
<p>Thread is new low-power protocol for Matter (and therefore IoT
devices, i.e. mesh network). Similar to Zigbee and Z-Wave</p>
<p>hierarchy:topology p2p:(mesh, bus) client-server:star</p>
<p>Advent of more software in cars has led to subscription based
services, e.g. heated seats. However, adding software increases
complexity: * Will lack of connectivity (e.g., no cell coverage where
you’re at) mean that the features are disabled until you get back into
cell range? * Can the servers be DOS’d so that nobody’s seat heaters
work? * If I pay for a subscription and sell a car, does the
subscription stay with the car? Or will it be like Tesla’s approach,
where the new owner has to pay to unlock the software features, even if
the previous owner paid? * What if there is a bug on the server that
incorrectly reports my subscription status? Will I be refunded, fully or
partially? * What happens when you can’t get in touch with customer
support because your subscription isn’t being properly detected on the
hardware? * What happens if the hardware breaks, but you’ve paid for the
subscription? Is repair to heated seats covered under terms of the
subscription, or will that be pushed to owners? * What happens if this
strategy is used by a smaller company than BMW, who suddenly goes out of
business and bricks your otherwise perfectly working hardware due to
shutting down servers?</p>
<p>Are big-tech companies realising the flaws in their ‘Simplicity
Sprints’ culture? Slowing hiring, realising they have way too many
employees</p>
<p>BCI (brain computer interfaces) are a real future</p>
<p>Unfortunate that ‘true security’ makes things more complex and
inconvenient, e.g. yubikey</p>
<p>Physics head-scratcher: dark matter makes up 80% of universe, yet we
can’t detect it?</p>
<p>Meta releasing AI chatbot to wild has again resulted in racist and
sexist comments</p>
<p>More evidence of contrasting quality between modern hardware and
software with worldwide Google outage caused by software update</p>
<p>Oncall software engineers akin to casual teachers</p>
<p>What are FPGAs and how do they allow the creation of hardware for
emulating old games like GBA? EU enforcing USB-C forces Apple to switch
to USB-C. Yay!</p>
<p>Oh dear, Java is not dying out (state of the octoverse)</p>
<p>Realise I’m highly misanthropic Frequent STMicroelectronics
newsletter coverage of IoT (and the many, many protocols) and machine
learning indicative of trend in industry</p>
<p>Hi-fi audio. Newer terms to mean higher fidelity/data resolution new
OLED TVs (contrast, blacks). QLED/QNED (brightness) is a adding a
‘quantom dot’ layer into the white LED backlight LCD sandwich</p>
<p>5.1 means 5 speakers, 1 subwoofer woofer, subwoofer, speaker,
tweeter</p>
<p>Things getting smaller and more data, e.g. ‘normal’ sized VR
headsets</p>
<p>I really don’t see fold phones as necessary…</p>
<p>Are we moving down the road of homogenous, e.g. specifically target
CPU or GPU or hetereogenous programming, e.g. CUDA</p>
<p>Although a update pathway is provided from 20.04 to 22.04, I’m
reluctant to do so due to possible configuration issues. Why I chose LTS
5 year support (2025)</p>
<p>Interesting maglev trains reach amazing speeds and produce minimal
noise due to lack of friction</p>
<p>Interesting blood transfusions from older mice to younger mice, the
younger mice display characteristics of old mice</p>
<p>Bitcoin is a Ponzi scheme as almost no one actually uses it in
transactions, and is purely speculative. Does not create anything.
Interesting manifestation of capitalism.</p>
<p>Moore’s law number of transistors doubles every 2 years. Although not
strictly true, general trend is holding. Proebsting’s law states that
compiler improvements will double program performance every 18 years.
Therefore, cautious about the performance benefits a compiler brings.
Focusing on programmer productivity is more fruitful In general, newer
compilers take longer to compile, but produce slightly faster code maybe
20% faster.</p>
<p>Cyberdecks are evidence that the trend of going smaller isn’t always
aesthetic</p>
<p>Growing trend to have workstations operate in the cloud or
containerisation. For testing yes, for development however?</p>
<p>Strive towards much more potent nuclear fusion (100million°C)
reactors as oppose to nuclear fission (neutron splits Uranium, same as
original nuclear bombs)</p>
<p>Amazing that certain old rpm harddrives were susceptible to crashing
when ‘Rhythm Nation’ played as the resonant frequency was the same</p>
<p>Streaming outnumbering cable and broadcast TV</p>
<p>ripgrep a much faster and user friendly grep! unar will automatically
handle pesky non-folder archives</p>
<p>Interesting to see if mir wayland will take over xlib x11</p>
<p>Although the open nature of RISC-V gives it some economical
advantages, historically the ISA has not been the major driving factor
in widespread adoption. Rather, who invests the most in R&amp;D,
e.g. many places will develop ARM, with RISC-V go on your own.</p>
<p>Security an ever present issue, e.g. every Ubuntu weekly newsletter
get a list a security updates</p>
<p>Privacy laws prevent recording keystrokes in app, however can record
other information like time between keypresses etc. to identify you,
e.g. TikTok</p>
<p>Chiplets connection of chips. So, can build chiplets that aren’t SoC,
e.g. just CPUs and SoCs without chiplets Intel R&amp;D into chiplet
technology stacking presents it as a future possibility (Apple already
uses it with two M1 max chips to M1 ultra)</p>
<p>ACM (Association for Computing Machinery) Turing Award is essentially
Nobel Prize for Computer Science. Not applicable for me as awards
largely for academic contributions like papers/reports published e.g
data abstraction (Liskov substitution, Byzantine fault tolerance),
parallel computing (OpenMP standard). In some sense, the modern day
Booles and Babbages I’m more concerned with engineering feats in
software products.</p>
<p>An unfortunate reality of open tech, AI being used to make paywalls
‘smarter’</p>
<p>Read a Google research project on removing noise in photos.
Investigate source to test and am completely put off by the amount of
dependencies involved: conda (why not just whole hog and docker),
python, jax for TPU (python to tensor processing unit), external
repositories This also applied to the ‘amazing’ AI image generator
Stable Diffusion (I suppose high VRAM requirements also) Docker has uses
in CI</p>
<p>AI for everything dogma is becomming more pervasive with ‘clusters’
to train model. Although Tesla can build a supercomputer to train, like
all dogmas, not applicable to everything (readability, debugging goes
down)</p>
<p>Even air-gapped computers are not safe from sniffing</p>
<p>Seems that any in-demand tech device subject to bot scalping</p>
<p>As Moore’s law is widening, i.e. was 2 years now 4 years, companies
creating own hardware, e.g. YouTube chip to handle transcoding</p>
<!-- SPDX-License-Identifier: zlib-acknowledgement -->
<p>sudo apt-get update sudo apt-get -y upgrade sudo apt-get -y
install<br />
gcc<br />
make<br />
pkg-config<br />
apt-transport-https<br />
ca-certificates</p>
<p>if ! [ -f /etc/modprobe.d/blacklist-nouveau.conf ]; then echo
“nouveau is not blacklisted, doing so and rebooting”</p>
<p># Blacklist nouveau and rebuild kernel initramfs echo “blacklist
nouveau options nouveau modeset=0” &gt;&gt; blacklist-nouveau.conf sudo
mv blacklist-nouveau.conf /etc/modprobe.d/blacklist-nouveau.conf sudo
update-initramfs -u # NOTE: fter rebooting we need to run this file
again sudo reboot fi</p>
<h1 id="check-if-nvidia-driver-is-installed">Check if nvidia driver is
installed</h1>
<p>if ! [ -f /usr/bin/nvidia-smi ]; then echo “nvidia driver is not
installed, installing” # Install NVIDIA Linux toolkit 510.54 wget
https://us.download.nvidia.com/XFree86/Linux-x86_64/510.54/NVIDIA-Linux-x86_64-510.54.run
chmod +x NVIDIA-Linux-x86_64-510.54.run sudo bash
./NVIDIA-Linux-x86_64-510.54.run rm NVIDIA-Linux-x86_64-510.54.run
fi</p>
<h1
id="install-cuda-toolkit-11.3-upgrade-1-for-ubuntu-20.04-lts">Install
CUDA toolkit 11.3 Upgrade 1 for Ubuntu 20.04 LTS</h1>
<p>wget
https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin
/etc/apt/preferences.d/cuda-repository-pin-600 wget
https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb
sudo dpkg -i
cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb sudo
apt-key add /var/cuda-repo-ubuntu2004-11-3-local/7fa2af80.pub sudo
apt-get update sudo apt-get -y install cuda</p>
<p>ssh-add -L or simply look in ~/.ssh directory (this is essential for
private key)</p>
<p>seems that packaged things in the cloud aren’t all that flexible,
e.g. ML-in-a-box cannot have independent components updated</p>
<p>important to run apt update on first running</p>
<p>have to use -O and enclose with “” for wget</p>
<p>annonyingly have to remove open source noveu driver also install cuda
not from apt repository</p>
<p>Based on what was trained (LAION 400M internet scraped image-text
pairs, which contains violent and sexual images (as oppose to DALLE-2)),
output may bias, e.g. nerd might bias towards wearing glasses</p>
<h1 id="array-away">Array Away</h1>
<h2 id="matching-pairs">Matching Pairs</h2>
<p>A quadratically scaling solution is intuitive However, as we know
every match is unique, linearly scaling solution obtained with a hash
map. C++ STL implementation of hash tables are sets (just keys) and maps
Unordered variants are raw hash maps Ordered use self-balancing
red-black-tree yielding logarithmic time Simplest hashing function
<code>(x &gt;&gt; 4 + 12) &amp; (size - 1)</code> Important to keep in
mind we are executing on a physical machine and that Big-Oh is a
‘zero-cost abstraction’ world. For example, the extra overhead of
introducing a hashmap (memory allocations/copies) will result in this
being slower for small lists (also no dynamic memory allocations in ISR)
This is why C++ STL uses hybrid introsort</p>
<h2 id="sorting-squared-array">Sorting Squared Array</h2>
<p>Quadratic insertion/bubble sort preferable for small lists Loglinear
divide-and-conquer merge/quick for medium Linear radix for large</p>
<h2 id="tournament-winner">Tournament Winner</h2>
<p>In cases space and size parameters different Can join linear
operations populate and min/max determination</p>
<!-- SPDX-License-Identifier: zlib-acknowledgement -->
<p>https://marketplace.fedevel.education/itemDetail.html?itemtype=course&amp;dbid=1569757838995&amp;instrid=us-east-2_KpwYC7yK5:45f6c01d-ccc8-43e0-8f33-c5a70caf707f</p>
<p>when creating lid lips, factor in printer tolerance, say 0.4mm</p>
<p>Spreadsheet (have dimensions to make parametric): if want to access
parameteric sketch constraint, &lt;<Sketch>&gt;.Constraints.name
(IMPORTANT: even though variable, make sure to reference it off the
sketch) GIVE OPTIONAL NAME SO CAN REFERENCE FROM .Constraints! (formula
typecasting may be necessary, e.g. (value<em>1mm)) </em>
printer_tolerance * container_l/w/h * board_offset_x/y * case_thickness
* base_thickness * hole_diametre_percent_ratio
(e.g. &lt;<Internal>&gt;.Constraints.height *
hole_diametre_percent_ratio) * global_chamfer</p>
<p>1.75mm PLA (polylactic acid) into 0.4mm nozzle</p>
<p>0.15mm layer height speed/quality 15% infill gyroid
integrity/speed/usage</p>
<p>supports required for model that does not print over itself</p>
<p>export g-code (like printer ISA?) to sd card</p>
<p>supports necessary for complex geometries like overhangs, greater
than 45°, etc. put supports everywhere by default? (perhaps add blockers
to this?) maybe just use everywhere to get a feel for it, then manually
add enforcers?</p>
<p>can also use printrun usb-b interface to print without SD card?</p>
<table style="width:8%;">
<colgroup>
<col style="width: 8%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">most solder has flux core (typically
rosin) to remove oxide films, i.e. wetting the metal (to remove
dirt/grease will require cloth or steel brush) Sn/Pb (60/40) lower
boiling point and shinier finish (cone shaped) then non-leaded. fumes
are flux as boiling point of lead (≈1700°C) much higher fume extractor
at top</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Don’t restrict right side of bell curve
Let your aces be aces Being an ace involves having an opinion Most
influential software written largely by one person, e.g Linux, Unix, git
etc. Then a team is assigned to maintain it. Fallacy about solo
programmer productivity requiring large teams. Design by committee
pushes design to middle of bell curve as opposing views average out</td>
</tr>
<tr class="even">
<td style="text-align: left;">Cpu try to guess what instructions ahead
(preemptive). Cost of incorrect reflushing expensive. So want to get rid
of conditional jumps. Ideally replace with conditional movs or
arithmetic branch less techniques. Endianness (register view), twos
complement (-1 all 1s) Branch less programming is essentially SIMD</td>
</tr>
<tr class="odd">
<td style="text-align: left;">What simd instructions available to cpu?
If variable clock speed, cpu could detect not using all cores and
increase single core clock</td>
</tr>
<tr class="even">
<td style="text-align: left;">Flops calculated with best instruction
set? Not memory bound is best case for hyper threading Intel speeds
optimised for gpr arithmetic, boolean and flops Why is Intel shr
instruction so slow? Intel deliberately makes mmx slow</td>
</tr>
</tbody>
</table>
<p>For intel CPUs, i3-i7 of same generation will have same
micro-architecture. Just more cache, hyperthreading, cores, die size
etc.</p>
<p>$(grub-)</p>
<p>Intel clock frequency is often changed by OS?</p>
<p>Is cortex-m4 microarchitecture? How does this relate to intel naming?
AMD also?</p>
<p>also have uOP cache considered L0</p>
<p>$(getconf LEVEL1_DCACHE_LINESIZE)</p>
<p>$(sudo lshw -html &gt; info.html) for RAM, harddrive and drivers of
things $(ldd –version) $(lsb_release -a), $(cat /etc/debian_version)</p>
<p>SATA ssd is the lowest grade ssd (however still 4 times
bandwidth)</p>
<p>storage devices: form factor (M.2 keying, PCIe), interface (SATAIII,
NVMe, PCIe), technology a single form factor may support multiple
interfaces, so ensure motherboard has appropriate chipset</p>
<p>DRAM refreshed periodically. SDRAM (synchronises clock speed with
memory speed). SDRAM. LPDDR4 (low-power; double pumping on rising and
falling edge of clock)</p>
<p>SRAM more expensive, faster, not refreshed, larger die size.</p>
<p>DIIM (dual in-line memory module) is form factor (wider bus) SODIMM
(small outline)</p>
<p>From $(cpuinfo) see that although 64bit cpu this is just what the
instruction set supports. As we have no need for 16 exabytes (tera,
peta, exa), the physical address size may be 39bits, and virtual size
48bits to save on unused transistors</p>
<p>$(cpu-x) for cache information per core</p>
<p>NUMA node relationship between CPU socket (location on motherboard)
and memory banks. So, say 2 sockets will probably have 2 NUMA nodes.
Therefore, not all physical memory directly accessible from 1 cpu
socket; will have to go through other socket to get it</p>
<p>Hyperthreads don’t increase number of instructions per second, rather
number of instructions that can be queued (so hyperthread like a
queue)</p>
<p>Caches, are instruction and data caches combined? What distinct
features in a core, e.g. shared caches? What additional features on one
capable of hyperthreading?</p>
<p>CPU could implement VT-x, but motherboard and bios must support this
as well? What additional features are present when CPU supports
this?</p>
<p>Cache probably 8-way as compromise between lookup and copy speed.
Flow of cache, is it check if from 8-way copy then L2 8-way or finish L1
entirely? If found, in L2 does it copy to L1?</p>
<p>Polymorphism is a single object that can be interpreted as having
various types. This can simply be a struct with unions and a type
field.</p>
<p>Never use setters/getters unless actually doing something. You’re
spending your entire day typing. If needing, replace variable name with
name_ to see where it was used.</p>
<p>You need to be self critical to be a good engineer</p>
<p>Caches are a way of minimising roundtrip time of RAM by putting
memory as close to the core that thinks will need it L1 closest, 1/2
cycles, 32k. Wikichip for more info Cpu will go to caches first</p>
<p>L1 can supply 2 cache lines per clock Instructions per clock, number
of work components, e.g. number of add components, cache line per
cycles, cache latency, agu (address resolver units) impose restrictions
A cache miss is simply stalling for an instruction. However, this may
not be an issue if we do other work, e.g. complex algorithm takes many
instructions hiding memory access for out of order cpu. If hyper
threading with two schedulers, if cache miss on one, just switch to the
other. Can really only know if a cache miss incurs a performance penalty
by looking at raw numbers from vtune, etc. Because of the scheduler,
it’s not as simple as just looking at memory sizes So, due to complex
overlapped/scheduling nature of modern CPUs can really only know if
cache miss incurs penalty with vtune Uop website displays table for
instructions</p>
<p>Currently good that most things are little endian with 64 byte cAche
lines, however some hardware guys Is going to come along and change it
back to big endian</p>
<p>Should be code of ethics in software to not create
bugs/inconveniences for users that couldve been avoided</p>
<p>An instruction of throughput 1 means issued every clock. As many
instructions take longer than 1 cycle, each core requires a scheduler to
see if it can execute something. View cpu as sections where there is
some distance to communicate.</p>
<p>Making some thing good takes time. However, if you have crazy design
practices it will also take longer You have to be reality based when
programming. That is in an engineering sense, to design something that
solves the problem you have People become attached to a way of
programming which doesn’t focus on solving the problem. They want to
build rube-goldberg machines Selectively attacking problems seriously
means you have a functional program quicker, whereby you can actually
decide if those other problems need to be addressed. Can defer hard
decisions later as they will be made better as you will have more
technical expertise and more context to work with</p>
<p>Testing is important. If you don’t write tests, your software doesn’t
work. However, write higher level system tests, not excessive unit
tests. More efficient and this is where bugs are likely to be. You often
have to remove code, so having unit tests just increases the volume of
code you have to write. Huge drain on productivity. Maybe for NASA. A
new paradigm should weigh up cost-benefit. Almost always the cost is
ignored and people gobble them up</p>
<p>To make computers better to use, have to simplify them on all
levels</p>
<p>Faster cpu like Apple’s m1 are irrelevant if software bad</p>
<p>Floating point math faster than integers</p>
<p>my style of programming and problems enjoy solving found in embedded,
e.g your constrained with the silicon not like in web where you just
build another data centre</p>
<p>Compiler works on file by file, so knows nothing about calls across
files. Therefore it generates object files which are partially
executable machine code with unresolved symbols. Linker merges these
object files and also adds extra header information so that the OS can
load our executable (or more specifically a kernel, e.g. linux)</p>
<p>Complete code coverage on the one hand is very thorough, however
don’t get a lot of engineering output. Furthermore, most bugs appear in
between systems not in units.</p>
<p>Best way to test is to release on early access. This checks hardware
and software, user may be running adobe acrobat which hogs cpu so
instruct them to kill it before running your game. Or maybe 20000 chrome
plugins. This is something a hardware lab can’t tell you</p>
<p>Process is allocated virtual memory space OS has mapping table that
converts these to physical addresses. Part of our processes address
space is pre-populated by the kernel program loader, e.g.  linux-vdso,
environment variables, etc. Kernel tunables: sudo sh -c ‘echo
kernel.perf_event_paranoid=0 &gt;&gt; /etc/sysctl.d/local.conf’ (sysctl)
User tunables: ulimit -a In virtual address space, have user space and
kernel space address ranges. A virtual address is mostly relating to
page table indexes and the last bit is a static offset (as for security
addresses are randomized)</p>
<p>To make an installer just fwrite your executable and then data files
appended with footer. Inside the exe, fread the exe and fseek based on
the static offset of the appended resources Bake resources in for
reliability only really</p>
<p>Packed files better as less OS operations performing expensive file
handles etc.</p>
<p>Programming about solving problem. overlooked by design philosophies.
If you don’t have any functionality, you don’t have a structural
problem</p>
<p>const is only useful if you find it catches bugs for you (maybe for
globals instead of using #defines) however, in terms of optimsations,
const is useless as you can cast const away. therefore, for me, const is
mostly just a waste of typing. however, have to use for strings in C++
In a similar vein, VLAs useful here (note that sizeof(array) and
sizeof(pointer) for calculating string array count)</p>
<p>distinct areas of memory in assembly are stack, heap and data
(globals)</p>
<p>direction of stack growth is often determined by CPU. if selectable,
then OS. eg. x86 is downwards ulimit -s for stack size</p>
<p>good practice to assign variable for syntatical reasons, i.e. more
readable, e.g Controller *controller =
&amp;evdev_input_device.controller;</p>
<p>getconf can list POSIX system configurable variables</p>
<p>don’t go through a ton of unecessary stdlib. malloc probably more
optimised for small memory size requests relative to overall code base,
interfacing with system calls is not that much code (and can be
reused)</p>
<p>if we try to access memory from an invalid page (not reserved or
comitted) will get segfault. only have to worry about errors that don’t
manifest themselves on every run of the program.</p>
<p>on x86, writing by 32bit faster than 8bit as less instructions in
general, the fastest way is to use the widest possible register that can
be operated on at once the speed of accessing the memory from cache is
pretty cheap for nearby regions</p>
<p>don’t make changes for conceptual cleanliness. end of the day, want
to make performant, bug free code in the shortest amount of time.</p>
<p>when programming some days you are off. this just means you’re going
to be debugging a lot</p>
<p>we want it to be clear what our code can and cannot touch. global
variables make this hard (however, can add _ to see where they are all
used) however, as many OSs are rather janky and most code will live
outside this, it is ok to have some globals here globals are fine in
development. can repackage into a structure later.</p>
<p>clock speed not as relevent as improvements in microarchitecture and
number of cores means can be more efficient under less duress. also,
lower clock speed may be because want to draw less power.</p>
<p>short build times (under 10 seconds) are incredibly important to not
decentivness making changes and testing them</p>
<p>function overloading, generalised operator overloading and default
arguments are c++ features that can’t easily be implemented with gcc
extensions</p>
<p>note that &gt;&gt; will typically (implementation defined) perform
arithmetic shift (fill in with 1’s) on signed, so not always the same as
a divide. similarly, sign-extension just fills in the new MSBs with
1’s</p>
<p>for large cross-platform projects, best to differentiate with
filenames, rather than ifdefs. this also gives the ability to have
different control flows across the different platforms (essential)</p>
<p>for a game, better to have the game as a service to the OS (not the
other way round). this is becuase the game does not need to know/perform
the myriad of possible operations the OS can perform.</p>
<p>most modern cpus have a floating point unit, making them faster than
ints (same latency), e.g. a multiply is one instruction where ints is
two (multiply and shift) x87 is the FPU instructions for x86 (also have
SSE instructions which is want you ultimately want) however, for
multiplayer games, optimisers can give different results when using
floating point, e.g a platform that has operator fusion like a MULADD
may give different result when rounding then a platform that has do it
separate. (fixed point could solve this)</p>
<p>Programming Mentality: always important to know when coding what is
your goal. premature optimisation and design are bad. your goal
dictactes the quality of the code you write, e.g. allowed to be janky as
first pass on API. write usage code first.</p>
<p>often when having a variable lengthed array, ask ourselves do we
really need that?</p>
<p>asserts are part of debug program that are used to check that things
work that should always work. use them for a condition that must be true
that is not explicitly present</p>
<p>don’t think about memory management, but rather memory usage. if
having to worry about freeing etc. done something wrong.</p>
<p>when writing ‘spec’ code, no need to handle all cases; simply note
down the edge cases you should handle later on stop yourself thinking
about whether the code is messy or not. only care once problem is
solved!</p>
<p>it’s not the programming practice but the dogma that gets you. when
you start to name things it almost always becomes bad. almost all
programming practices have a place, just not used often so RAII people,
in case of things that must be released, e.g DeviceContext, ok to use a
constructor/destructor pair. I’ll throw you a bone there</p>
<p>streaming i/o is almost never a good choice (hard drive slowest, more
errors)</p>
<p>compression orientated programming is you code what you need at the
time (breaking out into function, combining into struct, etc.) over time
the code marches towards a better overall quality</p>
<p>amdahls law gives the time taken for execution given a number of
cogives the time taken for execution given a number of cores. for this
formula (indeed any formula) we can obtain some property by seeing as
function parameter approaches infinity. in this case, the parallelising
part drops out. brooks law says that simply adding more people to a
problem does not necessarily make it faster. if requires great deal of
coordination/communication actually slows down.</p>
<p>solving a problem: 1. decide what you are doing (this can’t be
open-ended.) 2. organise groups to achieve this by making these
boundaries, we are presupposing that each part is separate, e.g tyres
team and engine team; assume tyres and engine cannot be one piece.
therefore, the boundaries define what products you can make, i.e. you
produce products that are copies of yourself or how you are structured
so, in software if we assign teams for say audio, 2d, 3d we would expect
individual APIs for each. the org chart is the asymptote, so it’s the
best case that we make a product as granular as our org chart. it could
be far worse and even more granular therefore, communication between
teams is more costly than communication within teams. takeaway is that
low-cost things can be optimised, high-cost can’t be (further away on
the org chart) note that communication in code could just be someone
checking something in and you pulling it what we are seeing now with
modern software is the superposition of orgcharts due to use of legacy
codebases now we see org charts in software, where people are
artifically creating inheritence hierarcies that limit how the program
works this is very bad. the reason it’s done is for people to create
mental models that help them solve the problem as they can’t keep the
complexity in their head. it may be necesary to solve the problem,
however it shouldn’t be looked at as good. however, because it’s done
due to lack of understanding, the delegation/separation is not done with
enough information. so you limit possibilities of the design space. so
although, libraries, microservices, encapsulation, package managers,
engines may be necessary due to our brain capacity (until neuralink or
we figure out a better way to do them) they are not good! we may use
hash map, but only in a particular way They limit optimisation as we
have already decided separation so always be on the lookout for times
when you don’t have to do these most people just download hundreds of
libraries because they know it works and they won’t be worse than any
one else. WE MUST BE LEAN AND FLEXIBLE IN ORGCHARTS IN COMPANY AND IN
SOFTWARE TO INCREASE DESIGN. some old codebases need to be retired</p>
<p>DO THE ‘MOST CERTAIN’ THING FIRST. THIS COULD EITHER BE THE
IMPLEMENTATION OR THE USAGE CODE choose data structures around solving
problem</p>
<p>some software is scaffolding, i.e. not shipped with the final
product, e.g. editor for games</p>
<p>To make anything alternate over time, just multiply by
sine(time);</p>
<p>Data hiding hides what the CPU is doing, which is what we care
about</p>
<p>Require machine-specific documentation files to understand system we
are on System specific ctags template projects, e.g. linux kernel,
glibc, etc. If using library, have ctags for that project</p>
<p>ALMOST ALWAYS CAST TO FLOAT WHEN DOING DIVISIONS LEADING TO FLOAT</p>
<p>Minimum value starts at max</p>
<p>Spreading out randomness:
<code>final_value += contrib * sample</code></p>
<p>If debug code (or code that will not be in release) use compile-time
macros</p>
<p>Use GLOBAL and global_prefix If casting is occuring, always be
explicit about it! Prefixing functions with sdl2_func() or linux_func()
only if intending to be cross-platform</p>
<p>With error handling, bad practice is to allow a lot of errors, which
brings in error classes etc. Instead, if it’s something that is actually
an error, e.g. missing file, write the code to explicitly handle it.
Handling the error in a sense makes it no longer an error, rather a
feature of the program</p>
<p>if function is expecting a range between, should we clamp to it?</p>
<p>Refactoring Mentality: Refactoring is essential. You must know what
you are trying to achieve so you have some notion of progress,
e.g. adding a constraint to the system. (Replacing variable type in
scope gives us all locations where variable was used, including macros.
This us where dynamic lnguages fail as you don’t know if you broke
something)</p>
<p>You can abstract/encapsulate anything at anytime, so why not do it
later when you know what you are doing? We want file format to be simple
and binary, unlike json which is general purpose and string</p>
<p>modifying (parse as pointer arg), returning (result struct). it is
best to put simple types are arguments rather than a group struct to
allow for maximum code reuse. only put group struct as arguments if must
be put together (in general don’t pack so don’t force user to create a
struct when they may already have the values)</p>
<p>if can go functional without sacrificing, saves you complexity down
the road. oftentimes simply utilising elements of functional programming
is good, e.g. no global state, only operating on parameters etc.</p>
<p>writing code guides you to the right design, e.g. made same call
-&gt; put into function; require args in function -&gt; struct; many
related functions together -&gt; organise related functions into own
file; (if thinking could be moved to another file, make comment sections
outlining code blocks to ease this process later on) etc. (these are
simple, compression changes), complex api -&gt; transient struct,
overload functions for internal/external use There are also large
changes that are more difficult, e.g.  sections of single value
interpreted differently -&gt; pack 2 variables into 1 (_ technique
useful here) same operations performed on pairs of variables -&gt;
vectors (as oppose to working with them as scalars) vectors are
particularly useful as without them repeated actions quickly become
intractable It can get messy at times, but always know that a clean
solution is out there and you will refine towards it Work threw the
error tree one at a time Important to throw in asserts for underlying
assumptions. Also for debugging be aware of ‘copy-pasta’, e.g. copying
variables will have same name for two parameters as didn’t replace
it</p>
<p>we don’t want to orient our code around objects (if anything,
algorithmic oriented). its about how you arrive at some code that
determines how good it is</p>
<p>excessive pre-planning and setting waypoints is really only useful if
you’ve done the problem before (which in that case you’re not really
designing) instead, we become a good pathfinder, learning to recognise
the gradient of each day of the journey. when write the simplest thing
and loft it out into good design later (in this explorative phase, if we
make an changes for efficiency reasons we have just introduced the
possibilities of bugs with no benefit)</p>
<p>only break into function when you know what you want, e.g. called
multiple times or code finalised and improved readability (in which case
a tradeoff is made between understanding functionality and
semantics)</p>
<p>Don’t be scared of mass name changing!! Before doing so, see all
places where name is used Don’t be scared of long list of compiler
errors. Work your way through them</p>
<p>Refactoring with usage code: just write out structures that satisfy
the usage code. If major rewrite use #if 0 #endif to allow for
successful compiling</p>
<p>refactoring just copy code into function that gets it to compile.
later, worry about passing information in as a parameter basic debug and
release compiler flags When refactoring, utilise our vimrc <C-F> all
files Also, just pull code out into desired function and let the
compiler errors guide you Returning multiple values, just return struct
To reduce large number of function parameters, put into struct</p>
<p>Debugging Mentality: debugging stepping through pass-by-pass.
inspecting all variables and parameters and verifying state of
particular ones. make deductions about state of variables, e.g
overflowed, uninitialised, etc. drop in asserts draw it out</p>
<p>being able to draw out debug information is very useful. time spent
visualising is never wasted (in debugger expressions also)</p>
<p>When debugging, look through variables and see if anything looks
ridiculous</p>
<p>When in debugger, go iteratively progress through variable values in
function and see if they look right We can isolate some area of the code
and say this is probably the problem Then investigate relevent
sub-functions, etc. This can be a long process with seemingly little
gains. The issue could be subtle, e.g. signed/unsignedness size,
function called rarely</p>
<p>Configuration files should be copied, not generated (becomes too
messy) Symlink to template files from projects</p>
<p>To begin, I ensured that I had a debugger from which I could easily
step through the application’s execution. In code, I was able to
programmatically set system and user breakpoints.</p>
<p>(mocking of syscalls for unit testing with file i/o)</p>
<p>For handling non-fatal errors, single line check. For fatal errors,
nest all preceding code (I have learnt to not be afraid of indentation
in this manner). (error handling in general, i.e. reduce ‘errors’ by
making them part of normal execution flow)</p>
<p>When performing the common task of grouping data, a few practices to
keep in mind. Use fixed sized types to always know about struct padding
(in fact, I like to extend this to all my code)</p>
<p>If wanting multiple ways of accessing grouped data, use union and
anonymous structs. Use an int to reference other structs,
e.g. <code>plane_index</code></p>
<p>If the data being grouped can only exist together (e.g. points), use
vectors. Put all structs related typedefs inside their own header file
for easy access.</p>
<p>As floats are an approximation, when comparing to 0.0f (say for a
denominator check) or negative (say for a square root) use a
tolerance/epsilon less-than/greater-than check. In fact whenever
dividing should always ask oneself “can the value be zero?” To be clear
about float to int casting, use a macro like truncate/round (think about
what if uneven divide) Due to mixed integer and float arithmetic going
to float, calculate integer percentages <code>val * 100 / total</code>
There is no need to overload the division operator as can do
<code>(* 1.0f / val)</code></p>
<p>For easy substitution, use single letter prefix names like
<code>output_h</code> and <code>output_w</code>. Convention for variable
arrays, e.g. <code>Planes plane[1]</code>, <code>planes</code> and
<code>plane_count (use ARRAY_COUNT macro here)</code> Put for loop
statements on separate line to help not be afraid of indentation.
Iterate over pixel space and then convert to say, world space for
calculations (normalisation and lerp) Aspect ratio correction is simply
rearranging a ratio. If we determine one side is larger, scale other.
Use “ ASCII code to print a status indicator. Only use const for char *
string literals stored in the data segment.</p>
<p>Endianness comes into play when reading/writing from disk (e.g. file
type magic value) and working directly with <code>u8 *</code>
(e.g. iterating through bytes of a u32)</p>
<p>MARKETING APP: f5bot.com,
https://github.com/lawxls/HackerNews-personalized I’m notified when
keywords related to “human wants thing, my app can do thing” appear on
HN, Reddit and Lobsters. If I can then contribute with information to
that discussion, I’ll also leave a link to my app. Don’t just self plug,
people (myself included) appreciate more detailed information on how
they can solve their own personal problem, instead of being thrown into
“here’s an app, figure it out”</p>
<p>even parity is to make it even, i.e. so if 5 1’s, even parity will
add a 1</p>
</body>
</html>
