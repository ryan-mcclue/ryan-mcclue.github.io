<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Musings</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Musings</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#check-if-nvidia-driver-is-installed"
id="toc-check-if-nvidia-driver-is-installed">Check if nvidia driver is
installed</a></li>
<li><a href="#install-cuda-toolkit-11.3-upgrade-1-for-ubuntu-20.04-lts"
id="toc-install-cuda-toolkit-11.3-upgrade-1-for-ubuntu-20.04-lts">Install
CUDA toolkit 11.3 Upgrade 1 for Ubuntu 20.04 LTS</a></li>
<li><a href="#array-away" id="toc-array-away">Array Away</a>
<ul>
<li><a href="#matching-pairs" id="toc-matching-pairs">Matching
Pairs</a></li>
<li><a href="#sorting-squared-array"
id="toc-sorting-squared-array">Sorting Squared Array</a></li>
<li><a href="#tournament-winner" id="toc-tournament-winner">Tournament
Winner</a></li>
<li><a href="#e-commerce" id="toc-e-commerce">E-COMMERCE</a>
<ul>
<li><a href="#branding" id="toc-branding">BRANDING:</a></li>
<li><a href="#store-creation" id="toc-store-creation">STORE
CREATION</a></li>
<li><a href="#marketing" id="toc-marketing">MARKETING</a></li>
</ul></li>
</ul></li>
<li><a href="#news---wrestle-the-scorpion"
id="toc-news---wrestle-the-scorpion">NEWS - Wrestle the
Scorpion</a></li>
<li><a href="#news---scaling-the-libra"
id="toc-news---scaling-the-libra">NEWS - Scaling the Libra</a></li>
<li><a href="#news---sagging-arrow" id="toc-news---sagging-arrow">NEWS -
Sagging Arrow</a></li>
<li><a href="#news---leo-the-lion-enters-the-pride"
id="toc-news---leo-the-lion-enters-the-pride">NEWS - Leo the Lion Enters
the Pride</a></li>
<li><a href="#news---goat-in-current"
id="toc-news---goat-in-current">NEWS - Goat in Current</a></li>
<li><a href="#news---aquatic-bearings"
id="toc-news---aquatic-bearings">NEWS - Aquatic Bearings</a></li>
<li><a href="#news---a-virgin-woman" id="toc-news---a-virgin-woman">NEWS
- A Virgin Woman</a></li>
</ul>
</nav>
<!-- SPDX-License-Identifier: zlib-acknowledgement -->
<p>sudo apt-get update sudo apt-get -y upgrade sudo apt-get -y
install<br />
gcc<br />
make<br />
pkg-config<br />
apt-transport-https<br />
ca-certificates</p>
<p>if ! [ -f /etc/modprobe.d/blacklist-nouveau.conf ]; then echo
“nouveau is not blacklisted, doing so and rebooting”</p>
<p># Blacklist nouveau and rebuild kernel initramfs echo “blacklist
nouveau options nouveau modeset=0” &gt;&gt; blacklist-nouveau.conf sudo
mv blacklist-nouveau.conf /etc/modprobe.d/blacklist-nouveau.conf sudo
update-initramfs -u # NOTE: fter rebooting we need to run this file
again sudo reboot fi</p>
<h1 id="check-if-nvidia-driver-is-installed">Check if nvidia driver is
installed</h1>
<p>if ! [ -f /usr/bin/nvidia-smi ]; then echo “nvidia driver is not
installed, installing” # Install NVIDIA Linux toolkit 510.54 wget
https://us.download.nvidia.com/XFree86/Linux-x86_64/510.54/NVIDIA-Linux-x86_64-510.54.run
chmod +x NVIDIA-Linux-x86_64-510.54.run sudo bash
./NVIDIA-Linux-x86_64-510.54.run rm NVIDIA-Linux-x86_64-510.54.run
fi</p>
<h1
id="install-cuda-toolkit-11.3-upgrade-1-for-ubuntu-20.04-lts">Install
CUDA toolkit 11.3 Upgrade 1 for Ubuntu 20.04 LTS</h1>
<p>wget
https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin
/etc/apt/preferences.d/cuda-repository-pin-600 wget
https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb
sudo dpkg -i
cuda-repo-ubuntu2004-11-3-local_11.3.1-465.19.01-1_amd64.deb sudo
apt-key add /var/cuda-repo-ubuntu2004-11-3-local/7fa2af80.pub sudo
apt-get update sudo apt-get -y install cuda</p>
<p>ssh-add -L or simply look in ~/.ssh directory (this is essential for
private key)</p>
<p>seems that packaged things in the cloud aren’t all that flexible,
e.g. ML-in-a-box cannot have independent components updated</p>
<p>important to run apt update on first running</p>
<p>have to use -O and enclose with “” for wget</p>
<p>annonyingly have to remove open source noveu driver also install cuda
not from apt repository</p>
<p>Based on what was trained (LAION 400M internet scraped image-text
pairs, which contains violent and sexual images (as oppose to DALLE-2)),
output may bias, e.g. nerd might bias towards wearing glasses</p>
<h1 id="array-away">Array Away</h1>
<h2 id="matching-pairs">Matching Pairs</h2>
<p>A quadratically scaling solution is intuitive However, as we know
every match is unique, linearly scaling solution obtained with a hash
map. C++ STL implementation of hash tables are sets (just keys) and maps
Unordered variants are raw hash maps Ordered use self-balancing
red-black-tree yielding logarithmic time Simplest hashing function
<code>(x &gt;&gt; 4 + 12) &amp; (size - 1)</code> Important to keep in
mind we are executing on a physical machine and that Big-Oh is a
‘zero-cost abstraction’ world. For example, the extra overhead of
introducing a hashmap (memory allocations/copies) will result in this
being slower for small lists (also no dynamic memory allocations in ISR)
This is why C++ STL uses hybrid introsort</p>
<h2 id="sorting-squared-array">Sorting Squared Array</h2>
<p>Quadratic insertion/bubble sort preferable for small lists Loglinear
divide-and-conquer merge/quick for medium Linear radix for large</p>
<h2 id="tournament-winner">Tournament Winner</h2>
<p>In cases space and size parameters different Can join linear
operations populate and min/max determination</p>
<p>GE (12): * gens * phys</p>
<p>Free Electives (36): * COMP8001 (elective) * COMP3331 (networks) *
COMP9032 (microprocessors)</p>
<p>Disciplinary/major (96): 66 (core) + 30 (electives) Change to default
COMPA1 (Computer Science) from COMPS1 (Embedded Systems) * COMP1511
(Programming Fundamentals) * COMP1521 (Computer Systems Fundamentals) *
COMP1531 (Software Engineering Fundamentals) * COMP2521 (Data Structures
and Algorithms) * MATH1081 (Discrete Mathematics) * MATH1131
(Mathematics 1A) * MATH1231 (Mathematics 1B)</p>
<ul>
<li>COMP4920 (Professional Issues and Ethics in Information
Technology)</li>
<li>COMP2511 (Object-Orientated Design and Programming)</li>
<li>COMP3121 (Algorithms and Programming Techniques)</li>
</ul>
<p>144UoC total: – COMP3900 (Computer Science Project)</p>
<!-- SPDX-License-Identifier: zlib-acknowledgement -->
<ol type="1">
<li>SPEED:</li>
</ol>
<ul>
<li>create models with newest sensors straight away</li>
<li>create new models all-the-time</li>
</ul>
<ol start="2" type="1">
<li>A BUSINESS IS SOMETHING THAT MAKES MONEY. THIS IS NUMBER 1 PRIORITY
NOT MONEY OUT</li>
</ol>
<ul>
<li>MUST KNOW HOW PEOPLE ARE GOING TO PAY YOU, E.G. PAYPAL, STRIPE AND
HOW ARE YOU GOING TO CONVINCE THEM (OFFER THEM A PROMISE, E.G YOU WILL
…)</li>
<li>don’t think about what costs money, e.g. make logo, make website,
registered trademark if no one paying you, not a business think about
what brings money in</li>
<li>have a website with models, prices and advertising “sorry because of
such high demand, have to wait few extra weeks for product” “in
meantime, here is a free gift”</li>
<li>money fixes problems, i.e. can go back and fix other problems that
cost money later, e.g. getting a registered trademark, getting an office
(money in is vanity)</li>
<li>you don’t need fancy things until PEOPLE START PAYING YOU MONEY</li>
<li>at least if no one buys from advertising, you haven’t lost
anything</li>
</ul>
<ol start="3" type="1">
<li>START BUSINESSES CHEAPLY. DON’T SPEND ON FULFILLMENT, SPEND MORE ON
MONEY IN FIRST</li>
</ol>
<ul>
<li>when you have large amounts of money, can make a lot of
mistakes</li>
<li>allows you to see what is viable without risk</li>
<li>can have cheap/basic products first then make better later</li>
</ul>
<ol start="4" type="1">
<li>UTILISE FAMILY AND FRIENDS.</li>
</ol>
<ul>
<li>they can work for free at the start.</li>
<li>younger people more knowledgable of social media, e.g. tiktok</li>
</ul>
<ol start="5" type="1">
<li><p>COMMAND PRESENTATIONAL RESPECT</p></li>
<li><p>SELL TO EXISTING CUSTOMERS</p></li>
</ol>
<ul>
<li>add-on product</li>
<li>email all customers on database with a discounted offer</li>
</ul>
<ol start="7" type="1">
<li>WORRY ABOUT LEGAL WHEN RICH</li>
</ol>
<ul>
<li>all we need is a domain and a website</li>
</ul>
<p>42:00 https://www.youtube.com/watch?v=rRzM7MkppEo</p>
<p class="heading" id="section"></p>
<h2 id="e-commerce">E-COMMERCE</h2>
<p>Branding/idea and website are essential</p>
<p>find products from amazon, etsy, ebay, etc. however, only sell with
aliexpress as offers dropshipping methods, i.e. no packaging alibaba is
wholesale not dropshipping, i.e. must buy in bulk</p>
<p>paid ads on facebook, instagram, tiktok</p>
<p>for supplier, can get faster than aliexpress however cost more</p>
<p>add x3-x5 markup on product to pay for ever increasing advertising
cost</p>
<p>(buying in bulk will get faster shipping times) manually -&gt; DSers
app to automate purchases -&gt; sourcing agent be upfront with customers
regarding shipping time at the start (we are just testing,
i.e. consistent sales and proof of demand at the start, so long shipping
times are fine. just mention in FAQ or shipping policy etc.) (get
customisable product later, i.e. branded box as will have to pay in bulk
on Alibaba for them to do this)</p>
<p>Handling Returns: 1. damaged: get user to send photo, have them keep
the product, get supplier to ship another 2. ok: ask user to pay for
shipping costs back to you. then refund them</p>
<p>TikTok film yourself using a product, see if video can go viral
(whole skill in itself)</p>
<p>ads spend $50 per day. around $150-$200 to test a product until find
a winner</p>
<p>front-loaded time investment. once found good product, 30-60min per
day of ads (ads manager, metrics, etc.) 2-3 hours a day overall spend
daily time on product research (DEVELOP SKILLS TO FIND A PRODUCT THAT IS
WANTED AS A GOOD PRODUCT IS KEY), copyrighting, competitors, etc.</p>
<p>niche store</p>
<p>targeting impulse buyers, not value shoppers (so, sell under $100)
show innovative product with wow factor, they buy on the spot</p>
<p>if product out of stock, refund and send them a 10% discount code</p>
<h3 id="branding">BRANDING:</h3>
<p>digital age allows for microexperiments to test market, instead of
wasting capital on something that could fail (i.e. put advertising into
market first to see how customers react)</p>
<ol type="1">
<li><p>Test market We are only concerned with determing purchase intent.
Customer experience will initially be poor due to long shipping times.
Aliexpress -&gt; CJDropshipping, Spocket, Zendrop, uDroppy,
WiiO</p></li>
<li><p>Sourcing agent (when have 10-20 orders a day) Can reduce pricing,
faster shipping, custom packaging, thank you notes, etc.</p></li>
<li><p>Local fulfillment bulk buying and shipping to a 3PL (3rd party
logisitics)</p></li>
</ol>
<p>does it target niche customer (write down target audience and their
problems you are solving) get product that solves problem or adds value
to their life in a meaningful way product must have a unique selling
point high perceived value or problem solver, e.g. posture corrector
-&gt; solves problem vegetable slicer -&gt; adds value can’t be bought
in stores (not commonly advertised, not a basic product in store) (no
one will buy it from an unknown store if not unique) targeted to
customer niche lightweight and easy to ship possible to add markup pick
something that you have expertise in, allowing for easier market
research - health (back pain, sun-burn); pet supplies needs to have
WOW/UNIQUE-factor to GRAB ATTENTION IN AD</p>
<p>Have 5-10 products on website to build trust. Only put ads in for one
HERO PRODUCT at a time</p>
<p>DAILY RESEARCH TO SELECT PRODUCTS: TIME CONSUMING PROCESS TO
UNDERSTAND MARKET REGULAR ACTIVITY, NO OFF SWITCH - manual (see what
products are selling well on websites); Google Trends to verify search
volume for product - social media ads (follow big theme instagram pages,
initiate checkout to get ad algorithm to follow) - (START WITH THIS: spy
tools (combine previous 2)) - IMPORTANT: The only way to know if will
work is to test with your own ads. These are just indicators - identify
how much competitor selling for by reverse searching image As gain
experience, will see products over and over again, i.e. product
saturation (Google Trends can show this)</p>
<h3 id="store-creation">STORE CREATION</h3>
<p>Make website fit your brand before adding ads</p>
<p>Make sure domain is available before setting site name (short word
namelix.com) Also ensure domain is verified and web events prioritised
before ads?</p>
<p>Tracking essential before running ads, so as to better optimise ads
Facebook/tiktok pixels tracking code on website installable through
shopify app Google analytics as well</p>
<p>(Zoho) info@storename.com</p>
<p>Shopify payments (credit cards) and paypal (business account)</p>
<p>Shopify apps: * Fulfillment app: DSers -&gt; aliexpress
(CJDropshipping, S-pocket, weho, zendrop all have there own apps) *
Aftership (helps customers track order) * Klaviyo/SMSBump marketing
channels (email/text, e.g. abandoned cart emails etc.) * Vitals (Product
Reviews, Volume Discounts/Product Bundles (Upsells), Currency Converter,
Visitor Replays, Wheel of Fortune, Frequently Bought Together, Related
Products and Product Description tabs.) (want to save purchase
information to allow one-click purchasing if returning to increase LTV)
(offer discount in post-purchase emails) (GO INTO SHOPIFY AND MODIFY
CONFIRMATION EMAIL TO INCLUDE 24HR DISCOUNT CONFIRMATION EMAILS HAVE
100% OPEN-RATE)</p>
<p>Put shipping times at bottom of product page, shipping policies and
FAQs</p>
<p>Essential pages: Home Page, About Us, Product Pages, FAQs, Legal
Policies and Contact Us add a Shipping Policy and Track Your Order page
via the Aftership app</p>
<p>Conversion rate optimisation (if not getting sales, one of these
needs improving): * Product Photos (5-10 photos; flat-lays on
whitebackground and lifestyle someone using) initially source from
Aliexpress, alibaba, amazon (later down the track can: take photos
yourself, 3D realistic model from fiverr/upwork, get professional photos
etc.) * Pricing (Compare at Price on Shopify for discount offering?)
(Test free shipping. Perhaps best to offer free shipping over $X to
increase AOV) * Product Description Hero lines describing one core
benefit (i.e. how improve’s life) then 5 bullet-points describing more
features (i.e. what the product does) MAKE SURE BENEFIT IS
TANGIBLE/SPECIFIC AND METRIC BASED IF POSSIBLE, E.G 1000 songs in pocket
can look at real reviews and write description on their pain points *
Product Reviews (import reviews from Aliexpress via Vitals app and
ensure grammar is correct and have both good and bad reviews) (hero
product should have the most) * Website Speed (jpgs over pngs (crushpics
app), no videos, low number of apps)</p>
<p>Make sure have a 30day money-back garuntee. Ensure customers can
contact easily</p>
<p>Anything over 3% good conversion rate</p>
<p>landing page are more suited for digital products (and take a lot
longer to make) (can later do with say Shogun, zipify pages etc.)</p>
<h3 id="marketing">MARKETING</h3>
<p>Human beings are biologically programmed with 8 main desires:
Survival, food/drink, freedom from danger, sex, comfortable living
conditions, being superior to others, protection of loved ones and
social approval. Ads that target these will be subconsciously
watched</p>
<p>paid traffic and organic traffic (TikTok with someone using your
product. study and recreate competitor videos) AT LEAST $50 A DAY ON
ADS. $150-$200 TO TEST A PRODUCT (does not include $50 for ad creative)
run ads for 4-7 days to test (if perform terribly on day 1, then
probably kill earlier) (have to give time for ad algorithm to optimise
to find your buyers) should get sales within 1-3 days after this 4-7 day
period, choose to scale up or kill of ad-sets (terrible is 0.5% Link
CTR, and $3+ Link CPC maybe only wait 48 hours)</p>
<p>Facebook (includes Instagram) and TikTok (perhaps if targeting
younger audience) (tiktok does not require lots of followers to go
viral, just good content) Start with one platform, Facebook (king for
ecommerce due to data collection and targeted ads) With Facebook, set
feedback score to send after 8 weeks to ensure to not being blocked if
too many bad reviews</p>
<p>Goodle ads, Snapchat and Pinterest aren’t for impulse buyers (perhaps
explore Google ads when doing a branded campaign, e.g. people search for
your website)</p>
<p>If doing influencer marketing stick with theme pages as oppose to
personal brands, e.g. advertise on an instagram themed page?</p>
<p>Writing a blog and loading it up with keywords can drive ad-free
traffic by ranking in google searches. However, long and difficult
process</p>
<p>Need to have video ads first? Hire ad creatives on Fiverr #resources
section</p>
<p>Ad Metrics: INTEREST: * Link CPC (cost per click) how much it costs
for one person to click on your ad? (strive for under $1) * Link CTR how
many people click through to see website after ad (strive for over 1-2%)
(CPC and CTR correlated) ULTIMATE METRIC (if this profitable after 4-7
days, scale product): * Cost per purchase how much it costs for someone
to purchase on website?</p>
<p>For Facebook ads create a business account from main profile. Has to
be a real account not to get banned If get banned without doing anything
wrong, message and should be resolved 1-2 days * Don’t call out people
directly, e.g. ‘People have a problem’ over ‘you have a problem’ * No
outlandish claims</p>
<p>Add FB pixel helper extension to browser Before launching, click on
pages, add to cart, checkout and see if events are firing a pixel?</p>
<p>Let ad platforms optimise age/gender ad settings, so leave these
broad</p>
<p>Go after 1M audience size? Optimise for purchase? (ignore warnings
asking to optimise for funnel actions)</p>
<p>Start with (ABO) ad-set budget optimisation. Later might do CBO
(campaign budget optimisation)</p>
<p>1%, 3% etc. LLA (look-alike-audiences) target for people who have
already made purchases (best to do when say 300-500 events) (involves
creating a custom audience and targeting for them specifically?)</p>
<p>Improve CTR by testing new ad hooks (first 3 seconds to capture
attention. rest should keep attention till end. should be replayable.
copy competitors) Add more call to actions in the ad copy, i.e. add more
links If have successul ad-sets, modify the hooks of them an
rerelease</p>
<p>CPM (cost per 1000 impressions) is cost of ads, which is largely out
of your control. if you have better ads, i.e. more shares and views, the
cost of ads will be cheaper</p>
<p>Not getting sales, look at funnel: 1. Ad metrics (are people sharing,
etc.) 2. Website metrics (where’s the drop-off in customer activity) 3.
New product</p>
<p>Consider changing creatives or extend ad running time if breaking
even or slightly profitable, otherwise move on. don’t get attached to
products (a winning product is waiting out there)</p>
<h1 id="news---wrestle-the-scorpion">NEWS - Wrestle the Scorpion</h1>
<p>Make-A-Video AI seems promising</p>
<p>Good news first ever drug to slow down cognitive decline of
Alzheimer’s. Also drug to slow down ALS. Perhaps prolonging drugs first
step?</p>
<p>DreamFusion 2D-to-3D looks promising</p>
<p>Will future cars will be synced with mobile OSs from Apple or
Android? Already seeing start of this with CCC (Car Connectivity
Consortium) pushing smartphone car unlocking</p>
<p>Unfortunately malware spreads through low-hanging CVEs or social
engineering</p>
<p>Memory market collapse, i.e. a type of chip market</p>
<p>How nice that Apple’s anti-tracking crackdown only applies to
third-party apps</p>
<p>With the growth of hardware, really seems that adaptive learning
algorithms are going to be used instead of solving the problem
explicitly Perhaps AI solving the most-optimal implemention of an
algorithm is more appetising for me</p>
<p>More companies branching into GPUs with AI functionality, e.g. Intel
Arc, Acer etc. Furthermore, more companies branching into VR,
e.g. Lenovo, Facebook etc.</p>
<p>Is a smart ring really any better than a smart watch?</p>
<p>As you would expect, Raptor Lake CPUs faster single thread speed at a
lower wattage</p>
<p>Will it be common place for impaired actors like Bruce Willis to sell
likeness for deepfakes? In China, using virtual influencers.</p>
<p>Again, YouTube offers another thorn; restricting 4K access to
subscribers</p>
<p>MCUs that support OTA firmware updates will typically have built-in
key storage</p>
<p>Although decentralisation sounds good (own cell network etc.), it
requires user maintenance which people will pay others to do and we’re
back to square one in a way</p>
<p>How does Google Tensor G2 chip with various CPU architectures,
e.g. Cortex-A78, Cortex-A55, Cortex-X1 work?</p>
<p>OS’s designed for wearables, e.g. WearOS for Android. I suppose
wearables have become an established device class target?</p>
<p>It really isn’t tinfoil hat mentality to be wary of updating unless
necessary, e.g. most recent kernel patch affected Intel graphics
displays</p>
<p>Floating pod homes in Panama no one asked for.</p>
<p>In a literal sense Moore’s law is dead, however chiplets pose
interesting alternatives</p>
<p>Character.ai chatbot creator. In fact, AI editor/generators for most
artforms seems to exist (video runwayml)</p>
<p>The fluidity of OSs continues with new Ubuntu 22.04 replacing
PulseAudio with PipeWire, X11 with Wayland.</p>
<p>Having a live session USB is essential to always give root access to
filesystem</p>
<p>Can now get Ubuntu Pro for free, which is just extends LTS to 10
years</p>
<p>Fast GUI file searching with fsearch</p>
<p>Xbox streaming game console. High network speeds seems to make cloud
gaming more affordable. However, don’t like the idea of constant network
connectivity and the power of the provider to shut you out.</p>
<p>15th Century greatest appearance of ‘geniuses’. Despite access to
information, genius declined. Seems that require proffesional tutors at
young age to instill a human social engagement</p>
<p>Thanks to TCC compiler, can compile C in memory and load it, hence
using it in some way like a scripting language However, this can create
serious security holes. Could still use in a sandboxed process,
e.g. with libseccomp WASM allows to run a subset of C++/C (and well
anything that compiles to webassembly) in browser as a sandbox. Could
use with wasmer library Indeed, with WASM, can compile a native library
and use it on the browser like SQLite3</p>
<p>With the steady proliferation of VR gaming, it’s a good thing I was
not young during this time</p>
<p>DynamicPixelTuning (DPT) promises to make every pixel capable of
outputting all colours. Therefore, get 3 times resolution than having
combined rgb pixels</p>
<p>Very helpful ranger preview in conjunction with <code>rc.conf</code>
and <code>scope.sh</code></p>
<p>Apple more like a bank with savings account for Apple Card</p>
<p>Interesting new Danish political party with decisions made by AI. I
think AI as a collaborator is promising</p>
<p>Despite new phones offering a plethora of new features, don’t assume
that they are bug-free, e.g. pixel phone crash detection malfunctioning
on roller coaster, not allowing dialling to 000, etc.</p>
<p>Realise you can overclock RAM with Intel XMP (extreme memory
profile)</p>
<p>Although you hear new Apple and Microsoft chips, almost certainly ARM
under the hood</p>
<p>Intel NUC (next-unit-computing) just marketing term for small form
factors</p>
<p>Although largely unecessary now, Nvidia has lite hash rate which
impedes peformance in order to get GPUs into hands of gamers</p>
<p>The decline of the lone app, as Microsoft 365 leviathan</p>
<p>I see AR being more useful than VR, e.g. hololens for soldiers</p>
<p>Meta headset will use eye-tracking to position ads</p>
<p>Perhaps an emeritus professor I’m more willing to listen to.</p>
<p>What I used to take as prima facie from news outlets, now no
longer</p>
<p>Unfortantely UNSW basketball CC’d not BCC’d</p>
<p>To no one’s surprise, Windows updates nerf ryzen performance</p>
<p>Marketing plug for cloud gaming consoles when in fact standard phones
can do the same thing</p>
<p>With improved network performance, perhaps cheaper to offload
calculations to powerful servers (VDI: virtual desktop
infrastructure)</p>
<p>NB-IoT (narrowband, i.e. low power). Also have CoAP (constrained
application protocol) for embedded devices to access Internet</p>
<p>Easy to fall prey to the act of not adding anything useful to a
product, but simply adding IoT and calling it smart, e.g. smart
condom</p>
<p>HDR (high dynamic range) refers to colour spectrum. Implemented in
technologies such as Dobly Vision Dolby Atmos is a surround sound
technology</p>
<p>RCS seems to be better than SMS</p>
<p>Not really decentralisation with cloud, as many services just
operated by a handful of large companies (not what DARPA intended!)
Cloud is really just reduced complexity. It excels when application
simple and low traffic (managing a large application in the cloud is
just as difficult as on bare metal) Or, your traffic patterns are
unpredictable Otherwise, paying an unjustified premium Sold as computing
on demand (no complexity) when in reality, just renting computers at a
higher premium Let your talents to your own machines, rather than Amazon
or Google</p>
<p>Will NFC for door locks take hold?</p>
<p>AI for vaccine development sounds promising</p>
<p>Are the petabit speeds of research optical chip really that useful if
hardware can’t process that fast? Will radio only get us so far?</p>
<p>Probably better to use url-shortener service for sharing links</p>
<p>Perhaps explainpaper.com could break into reading programming
papers</p>
<p>More firm on not using Apple, e.g. Apple not allowing other
app-stores, taking revenue percentage of adds on apps, etc.</p>
<p>Bioengineered plants seem promising in say absorbing air
pollutants</p>
<p>Amazon continue to kibosh any semblance of non-monolopy now getting
into home insurance</p>
<p>Raptor Lake overclock to over 8GHz (however with liquid
nitrogen…)</p>
<p>With development of cheaper more powerful hardware, companies
introducing more ‘gaming’ brands e.g. Phillips new gaming monitor</p>
<p>Another cautionary tale to not update with Apple update nerfing ANC
earphones</p>
<h1 id="news---scaling-the-libra">NEWS - Scaling the Libra</h1>
<p>Xcode cloud subscription. oh no wasting so much time on naming of new
processes, e.g. ‘Developer Experience Infrastructure’</p>
<p>Another billionaire investing in a ‘utopian cities’ seems more
dystopic than anything. Promulgation of venture capitalists, angel
investors, etc.</p>
<p>PIC have weird instruction set, so generally have to use with
assembly over C compiler (no good free compiler) So, use AVR for low-end
like just LED driving? e.g. TLC5971</p>
<p>time-of-flight sensor like an infrared radar</p>
<p>over-current and over-voltage detectors for when using charging
devices, e.g USB-C charger? so, perhaps investigate/understand voltage
regulators? also have UVLO (undervoltage-lockout)</p>
<p>new USB-PD (power delivery) interface more power from USB-C</p>
<p>I can see machine learning ‘appropriate’ in say cleaning up random
noise, e.g. brain signals</p>
<p>interesting set of questions to inspect a software engineering
workplace:
https://neverworkintheory.org/2022/08/30/software-engineering-research-questions.html?utm_source=tldrnewsletter</p>
<p>things like database accelerator library indicative of normal
software not being fast</p>
<p>MOSFETs are a type of transistor. different transistors for say
quick-switching, low signal, high frequency, amplifier etc.</p>
<p>USB-4, PCI5, DDR5 emerging standards.</p>
<p>Could buy a GPU for running interesting machine learning applications
like Stable Diffusion (prompt engineers, oh dear…) https://www.krea.ai/
GPU structure similar to CPUs, e.g have cache, GDDR6 memory (more simple
parrellisation)</p>
<p>float-toy nice web visualistion tool</p>
<p>interestingly CRT can scale better than fixed-set resolution LCD</p>
<p>new TV monitor combination QD-OLED curved monitors less fatiguing as
physically matches our eye’s shape flexible/bendable monitors no one
asked for…</p>
<p>cool looking completely submerged server desktops. pure water is a
very good insulator (our tap water will have chlorine for example)
obtained via ozone treatment</p>
<p>the Nintendo DSi implemented augmented reality virtual reality is
completely immersive</p>
<p>how does wireless charging work without a pad, i.e. no induction
charging? interesting power sharing from phone to watch</p>
<p>trie -&gt; gzip. still have to decode and resulting memory same as
before compression succinct data structures are designed to not have to
be decoded, i.e. everything is stored as bits. ∴ uses a lot less memory
(however, only for larger datasets)</p>
<p>compound literals issues with debugger and maintanence</p>
<p>C11 static assertions, how to use? performance improvements? static
const char sound_signature[] = { #embed &lt;sdk/jump.wav&gt; };
static_assert((sizeof(sound_signature) / sizeof(*sound_signature)) &gt;=
4, “There should be at least 4 elements in this array.”); anonymous
structs int fnc(int arr[static 2])</p>
<p>C23 can prevent VLA by defining constexpr true, false keywords
nullptr (it’s a pointer not number) enum e : unsigned short { x }; digit
separators function attributes</p>
<p>smarter devices not necessarily better, e.g. printer’s with
end-of-life software</p>
<p>lol, ferrocene is a developing rust toolchain</p>
<p>PLC more expensive microcontroller that is more versatile,
e.g. handle voltage overload (often used in assembly lines)</p>
<p>removing shared pointers probably gives later code in the pipeline a
small cache boost as all the data is now co-located excessive logging
cause for bad performance excessive heap usage bad for performance if on
an OS note there is static, stack and heap memory areas</p>
<p>lol, killedbygoogle.com. perhaps not wise to rely on new services</p>
<p>is self-administration the only benefit of an inhaled COVID
vaccine?</p>
<p>doesn’t seem like quantum computers will be able to solve any
practical tasks (unless program exploits quantum parrelism to a large
extent)</p>
<p>cloud computing with containers growing, e.g. AWS/Azure ➞ Kubernetes
➞ docker</p>
<p>it’s sad, but you really could do a stand-up of modern software
projects, e.g. “introducing Goliath, an automatic external dependency
manager. under the hood we use a Nextrus package manager. can be
scripted with Freasy language extension of Frosty core language”</p>
<p>seems a lot of phones adding satellite connectivity even though it’s
much slower</p>
<p>although space travel seems like the future, how to cope with serious
health affects like space radiation</p>
<p>opening up web pages from tech news sites just awful. inudated with
floating content-blocking video ads, permanent marquee ads embedded
beween paragraphs and browser title bar flashing with bot message
notification, bot message popup, cookies accept bar, …</p>
<p>asciinema useful terminal recording tool with website to host</p>
<p>potential for sim-locking being a thing of the past with a push to
eSIM cards</p>
<p>New AI that can edit videos with textual prompts The dramatic shift
in technology that mobile and cloud devices have brought is being
realised by natural language processing As text is seen as a universal
input in a lot of Unix programs, interesting possibilities.</p>
<p>eyes convert photons to electrochemical signal transduction converts
one energy form to another CCD (charged couple device; less noise, more
power, lower speed) and CMOS (consumer grade) common camera sensors
digital cameras convert photons to array of pixels, represented as
voltage levels quad pixel camera sensor combines four adjacent pixels in
this array</p>
<p>round design of new Nvidia GPU may be evidence for the 20-year
cyclical nature of fashion</p>
<p>amazing new 6GHz stock speed Intel CPU</p>
<p>although all crypto is ponzi scheme, it seems the goals of Ethereum
to perform secure financial transactions is headed in a better direction
than BitCoin. furthermore following The Merge, it does not rely on power
hungry mining. this is in term has led to a lot of 2nd-hand GPUs
flooding the market</p>
<p>avx512 cant actually get performance stated by Intel ‘marketing’ as
it causes heat up and cpu thermal throttles</p>
<p>good to see some work being done on the interopability of digital
wallets</p>
<p>in general, Occum’s razor approach to muscular issues</p>
<p>smart power homes whereby the source of the power can be discerned,
i.e. if it’s clean or not. extends to phone chargers with knowledge of
this</p>
<p>interesting Github Copilot Labs able to do rough translations between
languages</p>
<p>good to see (in some ways) hardware vendors pushing for AI standards
to allow for greater optimisation</p>
<p>ATM machines can be targeted for card-skimmers</p>
<p>possibility of sprite animation in terminal using chafa tool to
create ascii block art</p>
<p>Intel new naming scheme confusing using brand name as category,
i.e. ‘Intel Processor’ instead of ‘Pentium’</p>
<p>YouTube no respect for customers, running clandenstine experiment
running up to 5 ads at the start instead of spacing them out
Furthermore, Mozilla researchers found that buttons like ‘Stop
recommending’, ‘Dislike’ have next to no effect</p>
<p>Growing space economy with NASA ISS becoming privatised</p>
<p>Gaming phones with extended fans/cooling and amenable gripping
features</p>
<p>I suppose it would be kind of cool to travel in a plane going Mach
1</p>
<p>There can be such extremes in software, e.g. from programming
hardware in FPGA to writing natural-language descriptions for an AI to
convert to code</p>
<p>Cool 3D printing pens, although slow, can be used to say repair a
chipped brick</p>
<p>Cool USB SAMD boards (possible malware creation)</p>
<p>Amazing creations from AI from still images, videos, digital
assistants: https://threadreaderapp.com/thread/1572210382944538624.html
Companies like DeepMind, OpenAI chatbot AI used in UI testing GPU DLSS
(deep learning super sampling) is AI upscaling</p>
<p>Finally, alleviating ambigious USB 4.0 v2.0 naming scheme with
devices having clear USB 40Gbps, 240W printed on them</p>
<p>Compelled to investigate a service like paperspace in order to run
OpenAI and other AI projects</p>
<p>Promising Framework laptop build to easily repair in mind. However,
subpar experience</p>
<p>Teachers are fired for moonlighting</p>
<p>Record breaking DDos attacks, 17.2million requests per second,
3.4terabits per second, 809million packets per second</p>
<p>Google have size to challenge Dolby with new HD audio standard.
However, whilst seeming altruistic, is just so they don’t have to pay
Dolby licensing fees in their hardware</p>
<p>Interesting Domain Brokerage services to allow you to get already
used domains</p>
<p>Amount limiting will not work to prevent MFA fatigue attacks</p>
<p>Record-breaking figures acheived with overclocking can be decieving
as may employ high-end coolers or even liquid nitrogen</p>
<p>Still Windows updates break things, e.g. NVidia drivers</p>
<p>The inundation of Javascript web frameworks has provided a learning
point for adopting new technologies. In general, stick to familiar
technologies and only adopted bleeding edge later</p>
<p>Cool application of IoT:
https://hackaday.com/2015/11/24/building-the-infinite-matrix-of-tamagotchis/</p>
<p>Although lower-res, CDs aren’t lossy compressed like Bluetooth or
spotify.</p>
<p>Amazing gigabit speeds being sold for ISPs</p>
<p>Sad that bariatrics is even a field of medicine</p>
<p>Serverless is just a term for a caching server closer to clients</p>
<p>In the same unrequested vein as foldable PCs, now have slidable
PCs</p>
<p>Perhaps the going through graphical ASMR programming videos the
‘enjoyable’ remedy</p>
<p>More encompassing/combined sensors, e.g. AI vision sensor, gesture
detection sensor</p>
<p>Increased power of technology, developing perhaps faster interfaces,
e.g. search by photo, speech, etc.</p>
<p>sextempber cornucopia of condoms don’t have to be nostradamus to work
out parents parking in effect, most people’s journey to learning is
bespoke my engineering mind (which has been molded by experience)
results in largely ad hoc responses many positive social dealings at
university are unfortunately pyrrhic</p>
<!-- SPDX-License-Identifier: zlib-acknowledgement -->
<h1 id="news---sagging-arrow">NEWS - Sagging Arrow</h1>
<p>I believe decoding brain waves into functional output is major change
in my future</p>
<p>Unikernel has applications bundled inside kernel (so like eBPF) for
high performance</p>
<p>Amusing Dead Internet Theory that the Internet died around 2016 and
is now largely bots</p>
<p>Oh dear, javascript smart watch</p>
<p>Interesting 3D print to make diffusing sheet for say LEDs to create
different ambiences</p>
<p>AI now being used to improve compression algorithms</p>
<p>Amazing potential of ‘molecular computers’ to make drugs with precise
traits (could extend to human’s gaining amazing a priori skills)</p>
<p>JPEG XL better compression and lossy + lossless mode</p>
<p>Again, Microsoft updates not working. This time, not actually
properly applying vulnerability update</p>
<p>Interesting can just buy off the shelf drone and attach something
like an ESP32 to send data back to us</p>
<p>Cool program that sort of gamifies video conferencing allowing for
individual chats: gather.town</p>
<p>Like ‘Scrum Certification’ now with Matter have an official
certification process</p>
<p>Good work being done in legislating IoT labels, e.g. like nutrition
labels that give information sensor data collected by device</p>
<p>Have GPU microarchitectures like RNDA.</p>
<p>Chiplets seem future of shrinking size and expanding computing power,
now seen in GPUs They can be easily be recombined to create custom
designs</p>
<p>VSR (virtual super technology) has GPU scale to 4K and then downscale
if necessary to monitor’s resolution However, if want say 8K gaming,
will require a DisplayPort cable</p>
<p>Robots beginning to see more everyday use, e.g. waiters. Also, have
robots learn in the field, e.g. Texas University have robots walking
around campus</p>
<p>Resistive RAM uses analog memory cells to store more information with
less energy</p>
<p>GPT-4 upcoming text generation AI Perhaps text-to-speech, language
transcription too diverse to solve without AI, e.g. deepgram program</p>
<p>Although some people experience myocarditis after COVID vaccine,
myocarditis long been linked to a number of viral infections</p>
<p>Borg like spacecraft, i.e. cubesat now in orbit</p>
<p>Silicon carbide power supplies more efficient</p>
<p>AI requires high quality data, i.e. created by skilled individuals.
Also requires unique data. Might not have enough unique data in the
future</p>
<p>Unfortunate that Intel releasing software-defined-silicon,
i.e. pay-as-you-go to enable certain hardware features</p>
<p>Not even subtle that ads are no longer targeted for you, but rather
shills</p>
<p>Prompt engineers for many AI generators, e.g. text-davinci-3</p>
<p>GPU AI DLSS improve performance by offloading frame generation</p>
<p>Biodegradable sensors made out of organic circuitry proof of
concept</p>
<p>Watching me sleep on the floor is watching how the sausage is made in
regards to my posture</p>
<p>Serendipitously obtain a bokeh photo with my outdated phone
camera</p>
<h1 id="news---leo-the-lion-enters-the-pride">NEWS - Leo the Lion Enters
the Pride</h1>
<p>Politics are infiltrating areas of technology: * Rust toolchains on
embedded. Rust developers have explicitly tweeted saying technology will
always be political * NASA Artemis Accords have first line stating
primary focus on women and person of colour on Moon Leads down the path
of FSF, and in fact any cultural revolution which thinks it can do
whatever it wants in the name of the people. Although perhaps ad
hominem, experience has shown that they’re all polite until they’re
not.</p>
<p>Seems in with big-tech, marketing is often more important than the
underlying technology. 170km ‘The Line’ ecotopia, metaverse, telsa etc.
They make wild claims and the general public has no way of knowing the
facts behind them (perception vs reality) A scary thought is that in
this age, possible for self-sustaining narratives capable of deflecting
facts</p>
<p>ARMs open-model allowed vendors to implement custom MPUs that saw in
gain dominance over oher RISCs like MIPS and AVR.</p>
<p>Tech companies becoming conglomerate monopolies, e.g. tiktok music,
apple tv etc.</p>
<p>Much like the C++ standards committee, concerns of ‘ivory tower’
nature of smart home Matter standards</p>
<p>Seeing consequences of covid semiconductor demand in chip shortages.
Exacerbated by increase usage in automotive industry and large
dependence on foundries in Taiwan</p>
<p>Annoyed at the web: * Seemingly lack of awareness of bloated and
abstracted infrastructure * New technologies in the sphere are just
sensationalised titles with little substance e.g. homescreen social
media, css layout model and js frameworks</p>
<p>The importance of programming to a physical machine is paramount. The
underlying technology is always changing, e.g. arcade machines,
consoles, phones, watches, plastic 4bit processors</p>
<p>EU lawmakers want USB-C for all mobile devices to reduce e-waste.
Makes me postulate a technocracy.</p>
<!-- SPDX-License-Identifier: zlib-acknowledgement -->
<h1 id="news---goat-in-current">NEWS - Goat in Current</h1>
<p>Time-of-flight sensors can be used to detect water levels</p>
<p>EMV (europay, mastercard and visa) secure payment technology embedded
in credit card chip</p>
<p>Waited till USB-C becoming standard to introduce reversible USB-A
(achieved with movable plastic divider and duplicated pins) Intel
thunderbolt faster than USB-C, yet ports still look very similar</p>
<p>AI in sensors used to alter configuration to optimise power
consumption AI generated voice, text. Disney can now alter age AI
parsing of voice (natural language processing) In summary, generative AI
everywhere. In fact, with ChatGPT being able to explain technical
concepts, birth of AGI (artificial general intelligence) Perhaps this
could be used as a sort of offline search engine. In fact, ChatGPT
generate prompt for DALLE Whilst ChatGPT solves problems considering
computers as generalised machines, it seems eventually it will get
there. So, embedded probably the last the be tackled due to unique
systems</p>
<p>Genetic engineering in flora seems more appetising,
e.g. drought-resistance wheat, air purifing plants</p>
<p>Batcat tool is cat with syntax highlighting</p>
<p>Skeptical of announcements made by budget-starved laboratories
(e.g. universities) about breakthroughs for technologies decades away,
e.g. fusion There are often caveats and furthermore, commerciality is
most likely decades away</p>
<p>Seems that bipartisan government action required to fix rats nest of
drivers in modern OSs in a similar vein to EU enforcing anti-competitive
laws on Apple to allow third-party apps, USB-C etc.</p>
<p>Have to be careful not to engage in technological contempt culture,
e.g. language wars. As technology changes rapidly, address changes with
temperance</p>
<p>If social media was all RSS (really simple syndication), things would
be much simpler</p>
<p>We are in a ‘gig’ economy, i.e. contract work</p>
<p>Example of Apple silicon is M1 chip. Placing some Apple silicon
inside new removable monitors to use less power from attached
computer</p>
<p>Optical computing, i.e. analog uses less power excel at linear
algebra. Makes them ideal for machine learning</p>
<p>Is prompt engineering now an important skill, as oppose to a sad
state of affairs?</p>
<p>Would controlling the weather be nice? e.g. releasing sulfur to
reflect more sunlight</p>
<p>Medical developments not just better treatments but also easier
detection, e.g. Alzheimer via blood test Even still, immune diseases
like rheumatoid arthritis are more easily treated with drugs than
osteoarthritis</p>
<p>Home appliances with WiFi connectivity allow for remote updates,
e.g. LG dishwasher</p>
<p>Seems all phones will be satellite based in the future</p>
<p>Mass production to TMSC advanced 3-nm chip underway Unfortunately
most likely due to Samsung chips having low yield, they don’t have high
QA for voltage regulation as compared to TSMC</p>
<h1 id="news---aquatic-bearings">NEWS - Aquatic Bearings</h1>
<p>Interesting ‘vivovore’ found that is an organism that eats
viruses</p>
<p>Could the US China chip ban result in China becoming more
self-reliant in the future as it’s forced to invest in own chip
production?</p>
<p>Further proliferation of OSs, e.g. Touch Ubuntu, Edubuntu, Kubuntu
etc.</p>
<p>Google wants RISC-V as tier-1 architecture for Android. Part of
further push for open source usage so as to not pay licensing fees,
e.g. developing their own video codec etc.</p>
<p>Death of narrator with AI text to speech</p>
<p>Nvidia AI on certain GPUs can upscale older blurry videos</p>
<p>AI training on users that will eventually replace them, e.g. Adobe
tracking artists workflow, Github copilot, etc.</p>
<p>Interesting storing application state in base64 url. No server
required, and browser history becomes undo-redo</p>
<!-- SPDX-License-Identifier: zlib-acknowledgement -->
<h1 id="news---a-virgin-woman">NEWS - A Virgin Woman</h1>
<p>Thread is new low-power protocol for Matter (and therefore IoT
devices, i.e. mesh network). Similar to Zigbee and Z-Wave</p>
<p>hierarchy:topology p2p:(mesh, bus) client-server:star</p>
<p>Advent of more software in cars has led to subscription based
services, e.g. heated seats. However, adding software increases
complexity: * Will lack of connectivity (e.g., no cell coverage where
you’re at) mean that the features are disabled until you get back into
cell range? * Can the servers be DOS’d so that nobody’s seat heaters
work? * If I pay for a subscription and sell a car, does the
subscription stay with the car? Or will it be like Tesla’s approach,
where the new owner has to pay to unlock the software features, even if
the previous owner paid? * What if there is a bug on the server that
incorrectly reports my subscription status? Will I be refunded, fully or
partially? * What happens when you can’t get in touch with customer
support because your subscription isn’t being properly detected on the
hardware? * What happens if the hardware breaks, but you’ve paid for the
subscription? Is repair to heated seats covered under terms of the
subscription, or will that be pushed to owners? * What happens if this
strategy is used by a smaller company than BMW, who suddenly goes out of
business and bricks your otherwise perfectly working hardware due to
shutting down servers?</p>
<p>Are big-tech companies realising the flaws in their ‘Simplicity
Sprints’ culture? Slowing hiring, realising they have way too many
employees</p>
<p>BCI (brain computer interfaces) are a real future</p>
<p>Unfortunate that ‘true security’ makes things more complex and
inconvenient, e.g. yubikey</p>
<p>Physics head-scratcher: dark matter makes up 80% of universe, yet we
can’t detect it?</p>
<p>Meta releasing AI chatbot to wild has again resulted in racist and
sexist comments</p>
<p>More evidence of contrasting quality between modern hardware and
software with worldwide Google outage caused by software update</p>
<p>Oncall software engineers akin to casual teachers</p>
<p>What are FPGAs and how do they allow the creation of hardware for
emulating old games like GBA? EU enforcing USB-C forces Apple to switch
to USB-C. Yay!</p>
<p>Oh dear, Java is not dying out (state of the octoverse)</p>
<p>Realise I’m highly misanthropic Frequent STMicroelectronics
newsletter coverage of IoT (and the many, many protocols) and machine
learning indicative of trend in industry</p>
<p>Hi-fi audio. Newer terms to mean higher fidelity/data resolution new
OLED TVs (contrast, blacks). QLED/QNED (brightness) is a adding a
‘quantom dot’ layer into the white LED backlight LCD sandwich</p>
<p>5.1 means 5 speakers, 1 subwoofer woofer, subwoofer, speaker,
tweeter</p>
<p>Things getting smaller and more data, e.g. ‘normal’ sized VR
headsets</p>
<p>I really don’t see fold phones as necessary…</p>
<p>Are we moving down the road of homogenous, e.g. specifically target
CPU or GPU or hetereogenous programming, e.g. CUDA</p>
<p>Although a update pathway is provided from 20.04 to 22.04, I’m
reluctant to do so due to possible configuration issues. Why I chose LTS
5 year support (2025)</p>
<p>Interesting maglev trains reach amazing speeds and produce minimal
noise due to lack of friction</p>
<p>Interesting blood transfusions from older mice to younger mice, the
younger mice display characteristics of old mice</p>
<p>Bitcoin is a Ponzi scheme as almost no one actually uses it in
transactions, and is purely speculative. Does not create anything.
Interesting manifestation of capitalism.</p>
<p>Moore’s law number of transistors doubles every 2 years. Although not
strictly true, general trend is holding. Proebsting’s law states that
compiler improvements will double program performance every 18 years.
Therefore, cautious about the performance benefits a compiler brings.
Focusing on programmer productivity is more fruitful In general, newer
compilers take longer to compile, but produce slightly faster code maybe
20% faster.</p>
<p>Cyberdecks are evidence that the trend of going smaller isn’t always
aesthetic</p>
<p>Growing trend to have workstations operate in the cloud or
containerisation. For testing yes, for development however?</p>
<p>Strive towards much more potent nuclear fusion (100million°C)
reactors as oppose to nuclear fission (neutron splits Uranium, same as
original nuclear bombs)</p>
<p>Amazing that certain old rpm harddrives were susceptible to crashing
when ‘Rhythm Nation’ played as the resonant frequency was the same</p>
<p>Streaming outnumbering cable and broadcast TV</p>
<p>ripgrep a much faster and user friendly grep! unar will automatically
handle pesky non-folder archives</p>
<p>Interesting to see if mir wayland will take over xlib x11</p>
<p>Although the open nature of RISC-V gives it some economical
advantages, historically the ISA has not been the major driving factor
in widespread adoption. Rather, who invests the most in R&amp;D,
e.g. many places will develop ARM, with RISC-V go on your own.</p>
<p>Security an ever present issue, e.g. every Ubuntu weekly newsletter
get a list a security updates</p>
<p>Privacy laws prevent recording keystrokes in app, however can record
other information like time between keypresses etc. to identify you,
e.g. TikTok</p>
<p>Chiplets connection of chips. So, can build chiplets that aren’t SoC,
e.g. just CPUs and SoCs without chiplets Intel R&amp;D into chiplet
technology stacking presents it as a future possibility (Apple already
uses it with two M1 max chips to M1 ultra)</p>
<p>ACM (Association for Computing Machinery) Turing Award is essentially
Nobel Prize for Computer Science. Not applicable for me as awards
largely for academic contributions like papers/reports published e.g
data abstraction (Liskov substitution, Byzantine fault tolerance),
parallel computing (OpenMP standard). In some sense, the modern day
Booles and Babbages I’m more concerned with engineering feats in
software products.</p>
<p>An unfortunate reality of open tech, AI being used to make paywalls
‘smarter’</p>
<p>Read a Google research project on removing noise in photos.
Investigate source to test and am completely put off by the amount of
dependencies involved: conda (why not just whole hog and docker),
python, jax for TPU (python to tensor processing unit), external
repositories This also applied to the ‘amazing’ AI image generator
Stable Diffusion (I suppose high VRAM requirements also) Docker has uses
in CI</p>
<p>AI for everything dogma is becomming more pervasive with ‘clusters’
to train model. Although Tesla can build a supercomputer to train, like
all dogmas, not applicable to everything (readability, debugging goes
down)</p>
<p>Even air-gapped computers are not safe from sniffing</p>
<p>Seems that any in-demand tech device subject to bot scalping</p>
<p>As Moore’s law is widening, i.e. was 2 years now 4 years, companies
creating own hardware, e.g. YouTube chip to handle transcoding</p>
<ul>
<li><p>vinegar and bicarb for walls and drain cleaning</p></li>
<li><p>cool idea of SDR (software defined radio) and RF analyser
https://greatscottgadgets.com/sdr/1/
https://github.com/ainfosec/FISSURE</p></li>
<li><p>how does quantum computing work?</p></li>
<li><p>what frequencies/technologies are regulated like in ISM; by
extension what other regulations are there?</p></li>
<li><p>why floating point inaccuracies</p></li>
<li><p>examples of hardware virtualisation instructions/codecs?
(e.g. multiway MMU?)</p></li>
<li><p>vulkan renderer:
https://www.youtube.com/watch?v=BR2my8OE1Sc&amp;list=PL0JVLUVCkk-l7CWCn3-cdftR0oajugYvd&amp;index=1</p></li>
<li><p>how does something like red hat and android get around gplv2 of
linux kernel</p></li>
<li><p>the SIG introduces bluetooth 5 which states higher data rate,
long range BLE etc. are their decisions informed on techonology advances
(seems not to be the case with 4G LTE…)</p></li>
<li><p>Understand memory alignment and cost of unaligned accesses? (ABI
defines alignment of C types?) (is it due to common programmer workflows
and less transistors required?) for modern hardware, trying to read data
from an unaligned memory access can result in 2 reads and a combine so,
there are custom compiler options to specify alignment (declspec() for
stack, aligned_malloc for heap) why not just always automatically align
things? conserve space? when to use these alignment extensions? when
doing performance timing/tuning?</p></li>
<li><p>is distinction between a unicast (device to device), multicast
(device to some devices), broadcast (device to all devices) only
discernable in packet format, i.e. must be parsed by network card first?
are signal strength changed?</p></li>
<li><p>Software laws, e. G. Have 4k in name, but image quality 1080p,
Elon musk making false claims, Most dash cams same SoC, and image
sensor, just different housing Garmon products to use must sign up for
garmin account and agree to collection of data what are laws for
misinformation, e.g. tesla, ‘4k’ dash cams, stats misleading: M1 chip
faster (only faster than Intel based macs), we don’t track in
‘traditional’ ways, tiktok keylogger technology exists but not
using</p></li>
</ul>
<p>TODO: favourites tab for morning viewing videos: common sense
skeptic; techquickie; handmade podcast; network next</p>
<p>Resident Name Unit Number / 17 High Street University Terraces
Kensington NSW 2033 Australia</p>
<p>chefgood: 20 x $209 mymusclechef: 20 x $219 WELCOME20</p>
<p>dinner + lunch: $220 breakfast: $100 rent: $345 phone: $70</p>
<p>leftover: $265</p>
<p>salary: ≈$52,000</p>
<p>fortnightly: $1400 + quarterly: $4000 = weekly: $1000</p>
<p>communicating with busy people:
https://threadreaderapp.com/thread/1562510420644343810.html</p>
<p>thread local storage could be implemented hyper-threaded cpu?</p>
<p>computer science papers https://blog.acolyer.org/</p>
<p>QUESTIONS:</p>
<p>security so vast and not something I want to devote time to:
https://leveleffect.referralrock.com/l/JOHNHAMMON07/</p>
<p>the constellation we can’t see as it’s blocked by the sign is the
zodiac sign for that month not new territory to regain interest in the
past, e.g. renaissance grew interest in ancient greek astrology zodiac
latinized of zodiakos, meaning circle of animals (all zodiac names
latinized greek) vernal is beginning of astronomical year; daylight
starts getting longer until summer solstice. hence, spring is when
zodiac starts aries (march 20th) -&gt; ram taurus (april) -&gt; bull
gemini (may) -&gt; twin brothers cancer (june) -&gt; crab leo (july)
-&gt; lion virgo (august) -&gt; woman libra (september) -&gt; scales of
justice scorpio (october) -&gt; scorpion sagittarius (november) -&gt;
archer’s arrow capricorn (december) -&gt; goat aquarius (january) -&gt;
water bearer pisces (feburary) -&gt; opposing fish</p>
<p>IS IT POSSIBLE THAT AN ASSEMBLY INSTRUCTION LIKE RDTSCP COULD BE
TRAPPED BY PROGRAM LOADER?
https://eli.thegreenplace.net/2011/01/27/how-debuggers-work-part-2-breakpoints</p>
<p>NOTE(importance of reading programming papers…. after handmade
finished)</p>
<p>vector math routines (obtaining cross product from column vector
form) when drawing vectors in a physical sense, keep in mind they are
rooted at the origin (even if drawings show them across time) whenever
doing vector addition/subtraction, remember the head-to-tail rule (their
direction is determined by their sign). could also think that subtract
whenever you want to ‘go away’ from something dot product transpose
notation useful for emulating matrix multiplication unit circle, x =
cosθ dot product allows us to project a vector’s length onto a unit
vector dot product allows us to measure a vector on any axis system we
want by setting up two unit vectors that are orthogonal to each other
simple plane equation with d=0 will be through origin (altering d shifts
the plane up/down) cross product gives vector that is orthogonal to the
plane that the two original vectors lie on (length is |a|·|b|·sinθ). So,
really only works in at least 3 dimensions with units, e.g. for camera,
start with arbitrary ‘unit’ defintion. later move onto more physical
things like metres by applying a scaling factor to direction vector, can
move along it world space coordinates. camera position is based on
these. the camera will have its own axis system which we determine what
it should be and then use cross product based on what we want
understanding dot product equivalence with circle equation for
multiplication of vectors, be explicit with a hadamard function
(IMPORTANT have reciprocal square root approximation which is there
specifically for normalisation. much faster cycle count and latency than
square root)</p>
<p>noise is randomness. white noise is complete randomness. blue noise
(harder to generate) is randomness with limitations on how close
together points can be (more uniform)</p>
<p>pride cometh before the fall! six of one, half a dozen of the other.
have our cake and eat it too ad infinatum</p>
<p>Borrowing money: clear you’re the right person to give the money to.
Clear you understand what you’re doing and the game process is figured
out. Proof of you will complete it. Here is the game, why I’m good at
it, why people will like it and why I’m going to succeed at developing
it Interview ability to explain problems you have encountered on
projects</p>
<p>time -p; getrusage();</p>
<p>callbacks less CPU intensive than polling</p>
<p>Saying one instruction is faster than the other ignores context of
execution. e.g. mul and add same latency, however due to pipelining mul
execution unit might be full TLS vs atomics, e.g. TLS is series of
instructions determined by OS and compiler. Atomics depend on how other
cores are run and synchronising necessary with other cores So, must
measure which is faster for particular situation</p>
<p>use $(time) for single line, use $(ctime)</p>
<p>Can pin a thread to a core</p>
<p>Can run programs in kernel space with eBPF</p>
<p>Frequent context-switching will give terrible cache coherency</p>
<p>adding <code>restrict</code> also useful to prevent aliasing and
thereby might allow compiler to vectorise say array loops</p>
<p>Before cpus increased in single thread execution speed. Now more
cores. It’s a topic of research to convert single threaded into
multithreaded for emulation. This is why emulation of something like the
GameCube (powerpc) is slow. Furthermore, due to hardware irregularities
that programs relied on may take hundreds of instructions to emulate If
actually a simple translation, then should run close to native speed.
This is reality of emulating hardware with hardware</p>
<p>CISC gives reduced cache pressure for high-intensive, sustained
loops</p>
<p>log2(n) number of bits for decimal
https://en.algorithmica.org/hpc/cpu-cache/associativity/</p>
<p>using genetic algorithm/machine learning to optimise for us
https://zeux.io/2020/01/22/learning-from-data/</p>
<p>Cpu try to guess what instructions ahead (preemptive). Cost of
incorrect reflushing expensive. So want to get rid of conditional jumps.
Ideally replace with conditional movs or arithmetic branch less
techniques. Endianness (register view), twos complement (-1 all 1s)
Branch less programming is essentially SIMD</p>
<p>If variable clock speed, cpu could detect not using all cores and
increase single core clock</p>
<p>Not memory bound is best case for hyper threading Intel speeds
optimised for GPR arithmetic, boolean and flops Intel deliberately makes
mmx slow</p>
<p>Low cache associativity means fast lookup but a lot of misses and
thus eviction policy like LRU</p>
<p>Count cycles to counteract possible thermal throttling Hyperthreads
useful only if different execution unit Cpu reads memory from cache and
ram in cache lines (due to programmer access patterns). Each item in
cache set is cache line size</p>
<p>if apple computers use RISC ARM in M1, why CISC necessary? (only
because on Intel?) emphasis of CISC simplify assembly (e.g. more
addressing modes), thereby reducing size of binary? (reduce
instructions) and increase cache coherency RISC will require less
transistors to implement complex hardware but will make optimising
harder for compiler? single cycle instructions (reduce cycles per
instruction)</p>
<p>when looking at a pointer, to optimise compiler must know whether it
can assume it points to a local var or not. so, easier to eliminate
aliasing with non-pointers</p>
<p>when viewing from application in a sandboxed environment like a
phone, total RAM less than installed as portion reserved for kernel</p>
<p>simplistically RAM 50ns and HDD 10µs? faster to read than write</p>
<p>2.5bln * 8 (simd) * n (execution units) * 2 (cores) assuming
instructions have throughput of 1 so 64 / 4 gives how many floats per
second from L1 cache in general, not streaming from memory the entire
time (would probably hit a cache bandwidth limit)</p>
<p>// undefined behaviour if not true ALWAYS_INLINE void assume(bool
cond) { if(!(c)) {__builtin_unreachable()}; } times when manual inlining
is required: https://www.youtube.com/watch?v=B2BFbs0DJzw</p>
<p>Unless your in web where everything takes years to load, as single
threaded performance is largely stagnant you will have to utilise
parallelism if want performance. This is very difficult and like single
threaded code generic libraries which can actually be very specific will
create bloated in performing code based. Multithreading is building up a
new discipline to single threaded. There are a lot of pitfalls for
performance (balancing want things local, however must share to utilise)
If you care about performance for anything, you should care about cache
misses Memory bandwidth and caches are major reasons for a cup attaining
performance. You have to think about where does memory actually live and
how is it transferred around</p>
<p>Optimiser allows for lexical scoping of stack variables. However, for
optimiser to inline will have to get rid of pointers to prevent
aliasing</p>
<p>stack and heap memory are the same physical thing, so only more
efficient if memory was hot, i.e. recently touched</p>
<p>Computer faster than you think, e.g instructions, clock cycles,
cores. Very large With M2 drive should be quick</p>
<p>may be easier for optimising compiler to work with things passed by
value as oppose to pointer. so, if need to modify something may have to
return the value in a functional programming style. however, this is
error prone. compiler cannot optimise pointers, e.g. if setting two
values to same pointer, compiler cannot say that both the values are the
same as another pointer may point to the same address. this is
aliasing.</p>
<p>we see contiguous memory in virtual memory, however in physical
memory it is almost certainly going to be fragmented</p>
<p>compilers can auto-vectorize loops for us (and other operations if we
perform say 20 of them). so, floats will be twice as fast as doubles
(more space, even though same latency and throughput)</p>
<p>optimising is a very precise process. only do when you have code that
is working and you know will keep. games by their very nature are about
responsiveness, so optimisation and low-latency is important. I like
programming with this as a mentality.</p>
<p>with pure compiler optimisations, i.e. code we have not optimised
ourselves, a 2x increase is not unexpected. (code we optimised not as
much)</p>
<p>optimise for worst case (looking out on whole world) not best case
(in front of wall, don’t render what is behind). we care about highest
framerate, not lowest.</p>
<p>virtually never use lookup tables as ram memory is often 100x slower
(so unless you can’t compute in 100 of instructions)</p>
<ol type="1">
<li>Optimisation (this is rarely done due to time involved) Do
back-of-envelope calculations; look at algorithm to see if wasteful;
benchmark to see if hitting theoretical calculations and then use
timings etc. to isolate why our code isn’t hitting these theoretical
numbers Very importantly need to know what the theoretical maximum is,
which will be dependent on the program, e.g bounded by number of bytes
sent to graphics card, kernel stdout etc.</li>
<li>Non-pessimisation (do this all the time) Don’t introduce unecessary
work (interpreter; complex libraries; constructs like
polymorphism/classes people have convinced themselves are necessary) for
the CPU to do to solve the problem</li>
<li>Fake optimisation (very bad philosophy) Repeating context-specific
statements e.g. use memcpy as it’s optimised (however the speed of
something is so context specific, so non-statement), arrays are faster
than linked lists (again, so dependent on what your usage patterns are)
IMPORTANT: In programming, preface the suitability of something to a
particular environment/context</li>
</ol>
<p>When many people say too much effort involved in optimisation, they
are generally thinking of point 1</p>
<p>sometimes things should be running faster than they should, however
only so much we can replace e.g. the structure of many OSs are based on
legacy code, so simply outputting to stdout may go through shell then
kernel etc. also, may have to deal with pessimised libraries. in these
cases: * isolate bad code, i.e. draw hard boundary between your code and
theirs by caching calls to them * do as little modification to the data
coming in from them (no need to say put in a string class etc.)</p>
<p>People think that it’s slow, but it won’t crash (because of
interpreter) Performance is critical in getting people excited about
what you do, e.g. windows ce was laggy, iphone performant but less
features changes the market low latency is more desirable, even if less
features</p>
<p>count number of math ops in function and control flow logic that is
evaluated branches can get problematic if they’re unpredictable</p>
<p>inspecting measurements of microarchitecture consider latency and
throughtput (how much does it cost to start again) so, FMUL may have
latency of 11, however throughput of 0.5, so can start 2 every cycle,
i.e. issue again (cpus these days are incredibly overlapped even if
single-threaded) so throughput is more of what we care about for
sustained execution, e.g. in a loop</p>
<p>however, these numbers are all assuming the data is in the chip. it’s
just as important to see how long it takes to get data to the chip. look
at cache parameters for microarchitecture; how many cycles to get from
l1 cache, l2 cache, etc. when get to main memory potentially hundreds of
cycles</p>
<p>bandwidth of L1 cache say is 80 bytes/cycle, so can get 20 floats per
cycle (however, based on size of L1 cache, not really sustainable for
large data)</p>
<p>http://igoro.com/archive/gallery-of-processor-cache-effects/</p>
<p>(could just shortcut this and just see if flops is recorded for our
chip)</p>
<p>so, using these rough numbers we should be able to look at an
algorithm (and dissect what operations it’s performing, like FMULs),
know how much data it’s taking, and give a rough estimate as to how long
it could optimally take (will never hit optimal however) IT’S CRITICAL
TO KNOW HOW FAST SOMETHING SHOULD RUN</p>
<p>REASONS SOFTWARE IS SLOW: 1. No back-of-envelope calculations (people
aren’t concerned that they are running up to 1000 times slower thn what
the hardware is capable of) These calculations involve say looking at
number of math ops to be performed in the algoirthm and comparing that
to the perfect hardware limit 2. Reusing code (20LOC is a lot; use
things that do what you want to do, but not in the way you want them to
be done; often piling up code that is ill-fitting to what the task was,
e.g. we know this isn’t a regular ray cast, it’s a ray cast that is
always looking down) 3. When writing, thinking of goals ancillary to
task (not many places taught how to actually write code; all high level
abstractions about clean code there are thinking about templates/classes
etc. not just what does the computer actually have to do to do this
task?) (there is no metric for clean code; it’s just some fictional
thing people made up)</p>
<p>WHENEVER UNDERSTANDING CODE EXAMPLES: 1. COMPILE AND STEP INTO (NOT
OVER) IN DEBUGGER AND MAKE HIGH LEVEL STEPS PERFORMED look at these
steps for duplicated/unecessary work (may pollute cache). (perhaps even
asking why was the code written the way it was) could we gather things
up in a prepass, i.e. outside of loop? if allocating memory each cycle
that’s game over for performance. do we actually have to perform the
same action to get the same result, e.g. a full raycast is not
necessary, just segment on grid O(n·m) is multiplicative, not linear
O(n). big oh is just indication of how it scales. could be less given
some input threshold (big oh ignores constants, hence looking at
aymptotic behaviour, i.e. limiting behaviour) now, once code reduced,
look at minimising number of ops</p>
<p>cpu front end is figuring out what work it has to do,
i.e. instruction decoding</p>
<p>e.g simd struct is 288 bytes, 4.5 cache lines, able to store 8
triangles</p>
<p>understanding assembly language is essential in understanding why the
code might not be performing well</p>
<p>branch prediction necessary to ensure that the front-end can keep
going and not have to wait on the back-end</p>
<p>execution ports execute uops. however, the days of assembly language
registers actually mapping to real registers is gone. instead, the
registers from the uops are passed through a register allocation table
(if we have say 16 general purpose registers, table has about 192
entries; so a lot more) in the back-end this is because in many
programs, things can happen in any order. so to take advantage of this,
the register allocation table stores dependency chains of operations
(wikichips.org for diagram) from execution port, could be fed back into
scheduler or to load/store in actual memory</p>
<p>when looking at assembly, when we say from memory, we actually mean
from the L1 cache</p>
<p>xmm is a sse register (4 wide, 16 bytes); m128 is a memory operand of
128 bits ymm is 8 wide 1<em>p01 + 1</em>p23 is saying issue 1 microop on
either port0 or port1 and one microop on either port2 or port3 so, we
could issue the same instruction multiple times, i.e. throughput of
0.5</p>
<p>microop fusion is where a microop doesn’t count for your penalty as
it’s fused with another. with combined memory ops,
e.g. <code>vsubps ymm8, ymm3, ymmword ptr [rdx]</code> this is the case
so, if a compiler were to separate this out into a mov and then a sub,
not only does this put unecessary strain on the front-end decoder it
also removes microop fusion as they are now separate microops (important
to point out that I’m not the world best optimiser, or the worlds best
optimisers assistant, so perhaps best not to outrightly say bad codegen,
just say makes nervous)</p>
<p>godbolt.org good for comparing compiler outputs and possible
detecting a spurious load etc.</p>
<p>macrop fusion is where you have an instruction that the front-end
will handle for you, e.g. add and a jne will merge to addjne which will
just send the 1 microp of add through</p>
<p>uica.uops.info gives percentage of time instruction was on a port
(this is useful for determining bottle-necks, e.g. series of
instructions all require port 1 and 2, so cannot paralleise easily) so,
although best case say is issue instruction every 4 cycles, this
bottleneck will give higher throughput</p>
<p>some levels of abstraction are necessary and good, e.g. higher level
languages to assembly</p>
<p>Optimise: gather stats -&gt; make estimate -&gt; analyse efficiency
and performance</p>
<p>file size https://justine.lol/sizetricks
https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236630#236630</p>
<p>more important to understand how CPU and memory work than language
involved in an OS, you will get given a zero-page due to security
concerns</p>
<p>likely() macros for branch prediction compiler optimisations
(https://akkadia.org/drepper/cpumemory.pdf, pg 56)</p>
<p>recording information: We want to understand where slow with vtune,
amd uprof, arm performance reports Next, determine if IO bound, memory
bound etc.</p>
<p>To determine performance must have some stable metric, e.g. ops/sec
to compare to e.g measure total time and number of operations
Hyper-threading useful in alleviating memory latency, e.g. one thread is
waiting to get content from RAM, the other hyper-thread can execute
However, as we are not memory bound (just going through pixel by pixel
and not generating anything intermediate; will all probably stay in L1
cache), we are probably saturating the core’s ALUs, so hyper-threading
not as useful</p>
<p>Inspecting the assembly of our most expensive loop, we see that
rand() is not inlined and is a call festival. This must be replaced
Essentially we are looking for mathematical functions that could be
inlined and aren’t that are in our hot-path. When you want something to
be fast, it should not be calling anything. If it does, probably made a
mistake Also note that using SIMD instructions, however not to their
widest extent, i.e. single scalar ‘ss’. Want to replace with ‘ps’ packed
scalar</p>
<p>we have the option of constructor/destructor pairs if we want to
determine best possible time if all caches align etc. ‘hunt for
mininum’, e.g. record mininum time execution in loop iteration or re-run
if smaller time yielded alternatively, we could develop a statistical
breakdown of values (could see moments when kernel switches us out
etc.)</p>
<p>(IMPORTANT save out configuration and timing information for various
optimisation stages, e.g. ./app &gt; 17-04-2022-image.txt)</p>
<p>agnerfog optimise website ‘what’s a creel’</p>
<p>threading Observe CPU percentage use is not close to 100% For
multithreading, often have to pack into 64 bit value to perform single
operation on it,
e.g. <code>delta = (val1 &lt;&lt; 32 | val2); interlocked_add(&amp;val, delta)</code></p>
<p>When making multi-threaded, segregate task by writing prototype
‘chunk’ function, e.g. <code>render_tile</code> Then write a for loop
combining these chunk functions Before entering the chunk function, good
to have a configuration printout, e.g. num chunks, num cores, chunk dim,
chunk size, etc.</p>
<p>When dividing a whole into pieces, an uneven divisor will give less
than what’s needed. so <code>(total + divisor - 1) / divisor</code> to
ensure always enough. We will want this calculation to be in the last
dividing operation, e.g. tile_width then tile_count calculated, so use
on tile_count Associated with this calculation is clamping to handle
adding extra exceeding original dimensions For getting proper place in
chunk, call function wrapper for pointer location per row</p>
<p>(May have to inline functions?) Next we want to pass each chunk onto
a queue and then dequeue them from each logical core? So, have a
WorkOrder that will store all information required to perform operation
on chunk, i.e. all parameters in <code>render_chunk</code> function (may
also store entropy for each chunk, i.e. random number series) Then a
WorkQueue that contains an array of WorkOrders with total number
equalling number of chunks So, the original loop iterating of chunks now
just populates the WorkOrders Now in a while loop that runs while there
are still chunks to execute, we call the <code>render_chunk</code>
function and pass in the WorkQueue The <code>render_chunk</code>
function will increment the next_work_order_index and return true if
more to be done</p>
<p>When spawning the actual worker thread functions, have same while
loop calling the <code>render_chunk</code> function as for core 0 (the
amount of threads to spawn would think should be equal to number of
logical cores? however exceeding them may increase performance?) (this
debate of manually prescribing the core count applies to the chunk size
as well. perhaps the sweet-spot for my machine in balancing context
switching and drain out is to manually prescribe their size as oppose to
computing them off the core count) (Collating information into the
WorkQueue struct helsp for printing out configuration) (Setting up this
way, we can easily turn multithreading off)</p>
<p>As creating threads will require platform specific, put prototypes in
main.h and the implementations in linux_main.cpp Then include
linux_main.cpp based on macro definition of platform in the build script
at the bottom of main.cpp</p>
<p>hyperthreading, architecture specific information becomes more
important when in a situation where memory is constrained in relation to
the cache (hyper-threads share same L1-L2 cache)</p>
<p>volatile says code other than what is generated by this compiler run,
could modify this value. it’s required for multithreaded, as compiler
may not re-read value that it may have cached in a register if changed
elsewhere when incrementing volatiles, must use a
locked_add_and_return_previous_value (could return new value, just be
clear)</p>
<p>simd clamp can be re-written as min() and max() combination, which
are instructions in SSE Although looking at the system monitor shows
cpus maxed out, we could be wasting cycles, e.g. not using SIMD</p>
<p>Define lane width, and divide with this to get the new loop count Go
through loop and loft used values e.g. lane_r32, lane_v3, lane_u32
(IMPORTANT at first we are only concerned with getting single values to
work, later can worry about n-wide loading of values) (TODO the current
code has the slots for each lane generated, rather than unpacked. look
at handmade hero for this unpacking mode) If parameters to functions,
loft them also (not functions? just parameters? however we do
random_bilateral_lane() so yes to functions?) If using struct or struct
member references, take out values and loft them also,
e.g. sphere.radius == lane_r32 sphere_r; (group struct remappings
together) Remap if statement conditions into a lane_u32 mask and remove
enclosing brace hierarchy (IMPORTANT you can still have if statements if
they apply to lanes, e.g. if mask_is_zeroed() break;) (TODO for
mask_is_zeroed() we want the masks to be either all 1’s or 0’s) (call
mask_is_zeroed() on all masks to early out as often as possible to get a
speed up) Once lofted all if statements, &amp; all the masks into a
single mask (it seems if there is large amounts of code inside the if
statements, you don’t want to do it this way and rather check if needing
to execute?) (IMPORTANT to only &amp; dependent masks, e.g. if there is
an intermediate if like a pick_mask or clamp, then don’t include it, but
do the conditional assign directly on this mask) Then enclose remaining
assignments in a conditional assignment function using this single mask?
(conditional_assign(&amp;var, final_mask, value); this uses positive
mask to get source and negative mask to get dest?) (also discover the
work around to perform binary operations on floating point numbers) So,
by end of this all values operated upon should be a lane type? (can have
some scalar types if appropriate) We may have situation where some items
in a lane may finish before others. So, introduce a lane_mask variable
that indicates this. To indicate say a break, we can do (lane_mask =
lane_mask &amp; (hit_value == 0)); For incrementing, will have to
introduce an incrementor value that will be zeroed out for the
appropriate lane item that has finished. Have horizontal_add()? Next
once everything remapped create a lane.h. Here, typedef the lane types
to their single variants to ensure working before adding actual simd
instructions Also do simd helper functions like horizontal_add(),
mask_is_zeroed() in one dimension first Wrap the single lane helper
functions and types in an if depending on the lane width set (IMPORTANT
any functions that we are to SIMD, place here. if it comes that we want
actual scalar, then rename with func_lane prefix)</p>
<p>for simd typically have to organically transition from AOS to SOA</p>
<p>Debug in single lane, single threaded mode (easier and debugger
works) However, can increase lane width as needed (threading not so
much?)</p>
<p>For bitwise SIMD instructions, the compiler does not need to know how
we are segmenting the register, e.g. 4x8, 8x8 etc. as the same result is
obtained performing on the entire register at once. So they only provide
one version of it, i.e. no epi32 only si128 Naming convention have
types: <code>__m128 (float), __m128i (integer), __m128d (double)</code>
and names in functions:
<code>epi32/si128 (integer), ps (float), pd (double)</code> Overload
operators on actual wide lane structs (IMPORTANT remember to do both
orders, e.g. (val / scalar) and (scalar / val)) Also have conversion
functions</p>
<p>Lane agnostic functions go at bottom (like +=, -=, &amp;=, most v3
functionality) (IMPORTANT it seems we can replace logical &amp;&amp; and
|| with binary for same functionality in simd)</p>
<p>(IMPORTANT simd does not handle unsigned conversions, may have to cut
off sign bit, e.g. &gt;&gt; 1)</p>
<p>process of casting type to pointer to access individual bytes or
containing elements (used in file reading too)</p>
<p>(IMPORTANT masks in SIMD will either be all 1’s or 0’s. perhaps have
a specific name for this to distinguish?)</p>
<p>(IMPORTANT seems that not all operations are provided in SSE, like
!=, so have to implement with some bitwise operations)</p>
<p>SIMD allows divide by zeros by default? (because nature of SIMD have
to allow divide by zeroes?)</p>
<p>To get over the fact that C doesn’t allow &amp; floating point,
reinterpret bit paradigm <code>*(u32 *)&amp;a</code> as oppose to cast
(IMPORTANT in SIMD cast is reinterpreting bits, so the opposite of cast
in C)</p>
<p>caching https://akkadia.org/drepper/cpumemory.pdf 1. know cache sizes
to have data fit in it 2. know cache line sizes to ensure data is close
together (may have to separate components of structs to allow loops to
access less cache lines) i.e. understand what you operate on frequently.
may also have to align struct 3. simple, linear access patterns (or
prefetch instructions) for things larger than cache size</p>
<p>inline assembly (raw syscalls from github) HAVE TO INSPECT/VERIFY
ASSEMBLY IS SANE FIRST THEN LOOK AT TIMING INFORMATION inspecting
compiler generated assembly loops, look for JMP to ascertain looping
condition due to macro-op fusion (relevent to say Skylake), e.g. cmp-jmp
non-programmable instructions could be executed by the cpu similarly,
instructions that only exist on the frontend but exist programmatically
e.g. xmm to xmm might just be a renaming in register allocation table
also due to concurrent port usage, can identify parts of code as
relatively ‘free’ struct access typically off a [base pointer] in
assembly, 1.0f might be large number e.g. 1065353216 in assembly loop,
repeated instructions may be due to loop unrolling we might see: *
superfluous loading of values off stack * more instructions required,
e.g not efficiently using SIMD (often this exposes the misconception
that compilers are better than programmers; so better to handwrite
intrinsics)</p>
<p>comparing unoptimised assembly to ‘wc’ see noticeable speed increase.
example of non-pessimisation</p>
<p>Following the basic principles of non-pessimisation, I make a note of
the huge amount of cruft in the C STL. The output buffering, hidden
<code>malloc()</code> ‘optimisations’ (uncommitted memory, encounter
expensive page faults later; prefer reliability/clarity over
edge-performance benefits), OS line ending conversions, non-obvious use
of mutexes etc. Whilst these may seem like minor inconveniences, they
can be insidious for performance, e.g. <code>rand()</code> has a huge
call-stack that if we replace with a simple xor shift, results in 3x
speed up. Although easy to criticise, it may be the situation that the
CRT had to be that way because of C standards. To isolate use of the
CRT, wrap in functions so we can hopefully replace with system calls,
intrinisics, etc. Although generally okay to use STL, it forces you to
use their patterns (e.g. memory allocation, locks etc.). This is true
for STLs in general across all languages. Some may have bloatness from
other areas, e.g. C++ templates To avoid the compiler having to generate
a large export table of all functions, make them <code>static</code> To
avoid large amounts of linking and ∴ increase compilation time, have a
unity build. Furthermore, garunteed ability to inline functions (as with
multiple translation units, possible one might only have function
declaration and not definition) (issues may occur with slower
incremental builds when including 3rd party libraries; yet, can still
work around this possibly using ccache)</p>
<!-- SPDX-License-Identifier: zlib-acknowledgement -->
<p>https://marketplace.fedevel.education/itemDetail.html?itemtype=course&amp;dbid=1569757838995&amp;instrid=us-east-2_KpwYC7yK5:45f6c01d-ccc8-43e0-8f33-c5a70caf707f</p>
<p>when creating lid lips, factor in printer tolerance, say 0.4mm</p>
<p>Spreadsheet (have dimensions to make parametric): if want to access
parameteric sketch constraint, &lt;<Sketch>&gt;.Constraints.name
(IMPORTANT: even though variable, make sure to reference it off the
sketch) GIVE OPTIONAL NAME SO CAN REFERENCE FROM .Constraints! (formula
typecasting may be necessary, e.g. (value<em>1mm)) </em>
printer_tolerance * container_l/w/h * board_offset_x/y * case_thickness
* base_thickness * hole_diametre_percent_ratio
(e.g. &lt;<Internal>&gt;.Constraints.height *
hole_diametre_percent_ratio) * global_chamfer</p>
<p>1.75mm PLA (polylactic acid) into 0.4mm nozzle</p>
<p>0.15mm layer height speed/quality 15% infill gyroid
integrity/speed/usage</p>
<p>supports required for model that does not print over itself</p>
<p>export g-code (like printer ISA?) to sd card</p>
<p>supports necessary for complex geometries like overhangs, greater
than 45°, etc. put supports everywhere by default? (perhaps add blockers
to this?) maybe just use everywhere to get a feel for it, then manually
add enforcers?</p>
<p>can also use printrun usb-b interface to print without SD card?</p>
<table style="width:8%;">
<colgroup>
<col style="width: 8%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">most solder has flux core (typically
rosin) to remove oxide films, i.e. wetting the metal (to remove
dirt/grease will require cloth or steel brush) Sn/Pb (60/40) lower
boiling point and shinier finish (cone shaped) then non-leaded. fumes
are flux as boiling point of lead (≈1700°C) much higher fume extractor
at top</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Don’t restrict right side of bell curve
Let your aces be aces Being an ace involves having an opinion Most
influential software written largely by one person, e.g Linux, Unix, git
etc. Then a team is assigned to maintain it. Fallacy about solo
programmer productivity requiring large teams. Design by committee
pushes design to middle of bell curve as opposing views average out</td>
</tr>
<tr class="even">
<td style="text-align: left;">Cpu try to guess what instructions ahead
(preemptive). Cost of incorrect reflushing expensive. So want to get rid
of conditional jumps. Ideally replace with conditional movs or
arithmetic branch less techniques. Endianness (register view), twos
complement (-1 all 1s) Branch less programming is essentially SIMD</td>
</tr>
<tr class="odd">
<td style="text-align: left;">What simd instructions available to cpu?
If variable clock speed, cpu could detect not using all cores and
increase single core clock</td>
</tr>
<tr class="even">
<td style="text-align: left;">Flops calculated with best instruction
set? Not memory bound is best case for hyper threading Intel speeds
optimised for gpr arithmetic, boolean and flops Why is Intel shr
instruction so slow? Intel deliberately makes mmx slow</td>
</tr>
</tbody>
</table>
<p>Polymorphism is a single object that can be interpreted as having
various types. This can simply be a struct with unions and a type
field.</p>
<p>Never use setters/getters unless actually doing something. You’re
spending your entire day typing. If needing, replace variable name with
name_ to see where it was used.</p>
<p>You need to be self critical to be a good engineer</p>
<p>Caches are a way of minimising roundtrip time of RAM by putting
memory as close to the core that thinks will need it L1 closest, 1/2
cycles, 32k. Wikichip for more info Cpu will go to caches first</p>
<p>L1 can supply 2 cache lines per clock Instructions per clock, number
of work components, e.g. number of add components, cache line per
cycles, cache latency, agu (address resolver units) impose restrictions
A cache miss is simply stalling for an instruction. However, this may
not be an issue if we do other work, e.g. complex algorithm takes many
instructions hiding memory access for out of order cpu. If hyper
threading with two schedulers, if cache miss on one, just switch to the
other. Can really only know if a cache miss incurs a performance penalty
by looking at raw numbers from vtune, etc. Because of the scheduler,
it’s not as simple as just looking at memory sizes So, due to complex
overlapped/scheduling nature of modern CPUs can really only know if
cache miss incurs penalty with vtune Uop website displays table for
instructions</p>
<p>Currently good that most things are little endian with 64 byte cAche
lines, however some hardware guys Is going to come along and change it
back to big endian</p>
<p>Should be code of ethics in software to not create
bugs/inconveniences for users that couldve been avoided</p>
<p>An instruction of throughput 1 means issued every clock. As many
instructions take longer than 1 cycle, each core requires a scheduler to
see if it can execute something. View cpu as sections where there is
some distance to communicate.</p>
<p>Making some thing good takes time. However, if you have crazy design
practices it will also take longer You have to be reality based when
programming. That is in an engineering sense, to design something that
solves the problem you have People become attached to a way of
programming which doesn’t focus on solving the problem. They want to
build rube-goldberg machines Selectively attacking problems seriously
means you have a functional program quicker, whereby you can actually
decide if those other problems need to be addressed. Can defer hard
decisions later as they will be made better as you will have more
technical expertise and more context to work with</p>
<p>Testing is important. If you don’t write tests, your software doesn’t
work. However, write higher level system tests, not excessive unit
tests. More efficient and this is where bugs are likely to be. You often
have to remove code, so having unit tests just increases the volume of
code you have to write. Huge drain on productivity. Maybe for NASA. A
new paradigm should weigh up cost-benefit. Almost always the cost is
ignored and people gobble them up</p>
<p>To make computers better to use, have to simplify them on all
levels</p>
<p>Faster cpu like Apple’s m1 are irrelevant if software bad</p>
<p>Floating point math faster than integers</p>
<p>my style of programming and problems enjoy solving found in embedded,
e.g your constrained with the silicon not like in web where you just
build another data centre</p>
<p>Compiler works on file by file, so knows nothing about calls across
files. Therefore it generates object files which are partially
executable machine code with unresolved symbols. Linker merges these
object files and also adds extra header information so that the OS can
load our executable (or more specifically a kernel, e.g. linux)</p>
<p>Complete code coverage on the one hand is very thorough, however
don’t get a lot of engineering output. Furthermore, most bugs appear in
between systems not in units.</p>
<p>Best way to test is to release on early access. This checks hardware
and software, user may be running adobe acrobat which hogs cpu so
instruct them to kill it before running your game. Or maybe 20000 chrome
plugins. This is something a hardware lab can’t tell you</p>
<p>Process is allocated virtual memory space OS has mapping table that
converts these to physical addresses. Part of our processes address
space is pre-populated by the kernel program loader, e.g.  linux-vdso,
environment variables, etc. Kernel tunables: sudo sh -c ‘echo
kernel.perf_event_paranoid=0 &gt;&gt; /etc/sysctl.d/local.conf’ (sysctl)
User tunables: ulimit -a In virtual address space, have user space and
kernel space address ranges. A virtual address is mostly relating to
page table indexes and the last bit is a static offset (as for security
addresses are randomized)</p>
<p>To make an installer just fwrite your executable and then data files
appended with footer. Inside the exe, fread the exe and fseek based on
the static offset of the appended resources Bake resources in for
reliability only really</p>
<p>Packed files better as less OS operations performing expensive file
handles etc.</p>
<p>Programming about solving problem. overlooked by design philosophies.
If you don’t have any functionality, you don’t have a structural
problem</p>
<p>const is only useful if you find it catches bugs for you (maybe for
globals instead of using #defines) however, in terms of optimsations,
const is useless as you can cast const away. therefore, for me, const is
mostly just a waste of typing. however, have to use for strings in C++
In a similar vein, VLAs useful here (note that sizeof(array) and
sizeof(pointer) for calculating string array count)</p>
<p>distinct areas of memory in assembly are stack, heap and data
(globals)</p>
<p>direction of stack growth is often determined by CPU. if selectable,
then OS. eg. x86 is downwards ulimit -s for stack size (main executable
will have stack size listed in headers)</p>
<p>good practice to assign variable for syntatical reasons, i.e. more
readable, e.g Controller *controller =
&amp;evdev_input_device.controller;</p>
<p>getconf can list POSIX system configurable variables</p>
<p>don’t go through a ton of unecessary stdlib. malloc probably more
optimised for small memory size requests relative to overall code base,
interfacing with system calls is not that much code (and can be
reused)</p>
<p>if we try to access memory from an invalid page (not reserved or
comitted) will get segfault. only have to worry about errors that don’t
manifest themselves on every run of the program.</p>
<p>on x86, writing by 32bit faster than 8bit as less instructions in
general, the fastest way is to use the widest possible register that can
be operated on at once the speed of accessing the memory from cache is
pretty cheap for nearby regions</p>
<p>don’t make changes for conceptual cleanliness. end of the day, want
to make performant, bug free code in the shortest amount of time.</p>
<p>when programming some days you are off. this just means you’re going
to be debugging a lot</p>
<p>we want it to be clear what our code can and cannot touch. global
variables make this hard (however, can add _ to see where they are all
used) however, as many OSs are rather janky and most code will live
outside this, it is ok to have some globals here globals are fine in
development. can repackage into a structure later.</p>
<p>clock speed not as relevent as improvements in microarchitecture and
number of cores means can be more efficient under less duress. also,
lower clock speed may be because want to draw less power.</p>
<p>short build times (under 10 seconds) are incredibly important to not
decentivness making changes and testing them</p>
<p>function overloading, generalised operator overloading and default
arguments are c++ features that can’t easily be implemented with gcc
extensions</p>
<p>note that &gt;&gt; will typically (implementation defined) perform
arithmetic shift (fill in with 1’s) on signed, so not always the same as
a divide. similarly, sign-extension just fills in the new MSBs with
1’s</p>
<p>for large cross-platform projects, best to differentiate with
filenames, rather than ifdefs. this also gives the ability to have
different control flows across the different platforms (essential)</p>
<p>for a game, better to have the game as a service to the OS (not the
other way round). this is becuase the game does not need to know/perform
the myriad of possible operations the OS can perform.</p>
<p>most modern cpus have a floating point unit, making them faster than
ints (same latency), e.g. a multiply is one instruction where ints is
two (multiply and shift) x87 is the FPU instructions for x86 (also have
SSE instructions which is want you ultimately want) however, for
multiplayer games, optimisers can give different results when using
floating point, e.g a platform that has operator fusion like a MULADD
may give different result when rounding then a platform that has do it
separate. (fixed point could solve this)</p>
<p>Programming Mentality: always important to know when coding what is
your goal. premature optimisation and design are bad. your goal
dictactes the quality of the code you write, e.g. allowed to be janky as
first pass on API. write usage code first.</p>
<p>often when having a variable lengthed array, ask ourselves do we
really need that?</p>
<p>asserts are part of debug program that are used to check that things
work that should always work. use them for a condition that must be true
that is not explicitly present</p>
<p>don’t think about memory management, but rather memory usage. if
having to worry about freeing etc. done something wrong.</p>
<p>when writing ‘spec’ code, no need to handle all cases; simply note
down the edge cases you should handle later on stop yourself thinking
about whether the code is messy or not. only care once problem is
solved!</p>
<p>it’s not the programming practice but the dogma that gets you. when
you start to name things it almost always becomes bad. almost all
programming practices have a place, just not used often so RAII people,
in case of things that must be released, e.g DeviceContext, ok to use a
constructor/destructor pair. I’ll throw you a bone there</p>
<p>streaming i/o is almost never a good choice (hard drive slowest, more
errors)</p>
<p>compression orientated programming is you code what you need at the
time (breaking out into function, combining into struct, etc.) over time
the code marches towards a better overall quality</p>
<p>amdahls law gives the time taken for execution given a number of
cogives the time taken for execution given a number of cores. for this
formula (indeed any formula) we can obtain some property by seeing as
function parameter approaches infinity. in this case, the parallelising
part drops out. brooks law says that simply adding more people to a
problem does not necessarily make it faster. if requires great deal of
coordination/communication actually slows down.</p>
<p>solving a problem: 1. decide what you are doing (this can’t be
open-ended.) 2. organise groups to achieve this by making these
boundaries, we are presupposing that each part is separate, e.g tyres
team and engine team; assume tyres and engine cannot be one piece.
therefore, the boundaries define what products you can make, i.e. you
produce products that are copies of yourself or how you are structured
so, in software if we assign teams for say audio, 2d, 3d we would expect
individual APIs for each. the org chart is the asymptote, so it’s the
best case that we make a product as granular as our org chart. it could
be far worse and even more granular therefore, communication between
teams is more costly than communication within teams. takeaway is that
low-cost things can be optimised, high-cost can’t be (further away on
the org chart) note that communication in code could just be someone
checking something in and you pulling it what we are seeing now with
modern software is the superposition of orgcharts due to use of legacy
codebases now we see org charts in software, where people are
artifically creating inheritence hierarcies that limit how the program
works this is very bad. the reason it’s done is for people to create
mental models that help them solve the problem as they can’t keep the
complexity in their head. it may be necesary to solve the problem,
however it shouldn’t be looked at as good. however, because it’s done
due to lack of understanding, the delegation/separation is not done with
enough information. so you limit possibilities of the design space. so
although, libraries, microservices, encapsulation, package managers,
engines may be necessary due to our brain capacity (until neuralink or
we figure out a better way to do them) they are not good! we may use
hash map, but only in a particular way They limit optimisation as we
have already decided separation so always be on the lookout for times
when you don’t have to do these most people just download hundreds of
libraries because they know it works and they won’t be worse than any
one else. WE MUST BE LEAN AND FLEXIBLE IN ORGCHARTS IN COMPANY AND IN
SOFTWARE TO INCREASE DESIGN. some old codebases need to be retired</p>
<p>DO THE ‘MOST CERTAIN’ THING FIRST. THIS COULD EITHER BE THE
IMPLEMENTATION OR THE USAGE CODE choose data structures around solving
problem</p>
<p>some software is scaffolding, i.e. not shipped with the final
product, e.g. editor for games</p>
<p>To make anything alternate over time, just multiply by
sine(time);</p>
<p>Data hiding hides what the CPU is doing, which is what we care
about</p>
<p>Require machine-specific documentation files to understand system we
are on System specific ctags template projects, e.g. linux kernel,
glibc, etc. If using library, have ctags for that project</p>
<p>ALMOST ALWAYS CAST TO FLOAT WHEN DOING DIVISIONS LEADING TO FLOAT</p>
<p>Minimum value starts at max</p>
<p>Spreading out randomness:
<code>final_value += contrib * sample</code></p>
<p>If debug code (or code that will not be in release) use compile-time
macros</p>
<p>Use GLOBAL and global_prefix If casting is occuring, always be
explicit about it! Prefixing functions with sdl2_func() or linux_func()
only if intending to be cross-platform</p>
<p>With error handling, bad practice is to allow a lot of errors, which
brings in error classes etc. Instead, if it’s something that is actually
an error, e.g. missing file, write the code to explicitly handle it.
Handling the error in a sense makes it no longer an error, rather a
feature of the program</p>
<p>if function is expecting a range between, should we clamp to it?</p>
<p>Refactoring Mentality: Refactoring is essential. You must know what
you are trying to achieve so you have some notion of progress,
e.g. adding a constraint to the system. (Replacing variable type in
scope gives us all locations where variable was used, including macros.
This us where dynamic lnguages fail as you don’t know if you broke
something)</p>
<p>You can abstract/encapsulate anything at anytime, so why not do it
later when you know what you are doing? We want file format to be simple
and binary, unlike json which is general purpose and string</p>
<p>modifying (parse as pointer arg), returning (result struct). it is
best to put simple types are arguments rather than a group struct to
allow for maximum code reuse. only put group struct as arguments if must
be put together (in general don’t pack so don’t force user to create a
struct when they may already have the values)</p>
<p>if can go functional without sacrificing, saves you complexity down
the road. oftentimes simply utilising elements of functional programming
is good, e.g. no global state, only operating on parameters etc.</p>
<p>writing code guides you to the right design, e.g. made same call
-&gt; put into function; require args in function -&gt; struct; many
related functions together -&gt; organise related functions into own
file; (if thinking could be moved to another file, make comment sections
outlining code blocks to ease this process later on) etc. (these are
simple, compression changes), complex api -&gt; transient struct,
overload functions for internal/external use There are also large
changes that are more difficult, e.g.  sections of single value
interpreted differently -&gt; pack 2 variables into 1 (_ technique
useful here) same operations performed on pairs of variables -&gt;
vectors (as oppose to working with them as scalars) vectors are
particularly useful as without them repeated actions quickly become
intractable It can get messy at times, but always know that a clean
solution is out there and you will refine towards it Work threw the
error tree one at a time Important to throw in asserts for underlying
assumptions. Also for debugging be aware of ‘copy-pasta’, e.g. copying
variables will have same name for two parameters as didn’t replace
it</p>
<p>we don’t want to orient our code around objects (if anything,
algorithmic oriented). its about how you arrive at some code that
determines how good it is</p>
<p>excessive pre-planning and setting waypoints is really only useful if
you’ve done the problem before (which in that case you’re not really
designing) instead, we become a good pathfinder, learning to recognise
the gradient of each day of the journey. when write the simplest thing
and loft it out into good design later (in this explorative phase, if we
make an changes for efficiency reasons we have just introduced the
possibilities of bugs with no benefit)</p>
<p>only break into function when you know what you want, e.g. called
multiple times or code finalised and improved readability (in which case
a tradeoff is made between understanding functionality and
semantics)</p>
<p>Don’t be scared of mass name changing!! Before doing so, see all
places where name is used Don’t be scared of long list of compiler
errors. Work your way through them</p>
<p>Refactoring with usage code: just write out structures that satisfy
the usage code. If major rewrite use #if 0 #endif to allow for
successful compiling</p>
<p>refactoring just copy code into function that gets it to compile.
later, worry about passing information in as a parameter basic debug and
release compiler flags When refactoring, utilise our vimrc <C-F> all
files Also, just pull code out into desired function and let the
compiler errors guide you Returning multiple values, just return struct
To reduce large number of function parameters, put into struct</p>
<p>Debugging Mentality: debugging stepping through pass-by-pass.
inspecting all variables and parameters and verifying state of
particular ones. make deductions about state of variables, e.g
overflowed, uninitialised, etc. drop in asserts draw it out</p>
<p>being able to draw out debug information is very useful. time spent
visualising is never wasted (in debugger expressions also)</p>
<p>When debugging, look through variables and see if anything looks
ridiculous</p>
<p>When in debugger, go iteratively progress through variable values in
function and see if they look right We can isolate some area of the code
and say this is probably the problem Then investigate relevent
sub-functions, etc. This can be a long process with seemingly little
gains. The issue could be subtle, e.g. signed/unsignedness size,
function called rarely</p>
<p>Configuration files should be copied, not generated (becomes too
messy) Symlink to template files from projects</p>
<p>To begin, I ensured that I had a debugger from which I could easily
step through the application’s execution. In code, I was able to
programmatically set system and user breakpoints.</p>
<p>(mocking of syscalls for unit testing with file i/o)</p>
<p>For handling non-fatal errors, single line check. For fatal errors,
nest all preceding code (I have learnt to not be afraid of indentation
in this manner). (error handling in general, i.e. reduce ‘errors’ by
making them part of normal execution flow)</p>
<p>When performing the common task of grouping data, a few practices to
keep in mind. Use fixed sized types to always know about struct padding
(in fact, I like to extend this to all my code)</p>
<p>If wanting multiple ways of accessing grouped data, use union and
anonymous structs. Use an int to reference other structs,
e.g. <code>plane_index</code></p>
<p>If the data being grouped can only exist together (e.g. points), use
vectors. Put all structs related typedefs inside their own header file
for easy access.</p>
<p>As floats are an approximation, when comparing to 0.0f (say for a
denominator check) or negative (say for a square root) use a
tolerance/epsilon less-than/greater-than check. In fact whenever
dividing should always ask oneself “can the value be zero?” To be clear
about float to int casting, use a macro like truncate/round (think about
what if uneven divide) Due to mixed integer and float arithmetic going
to float, calculate integer percentages <code>val * 100 / total</code>
There is no need to overload the division operator as can do
<code>(* 1.0f / val)</code></p>
<p>For easy substitution, use single letter prefix names like
<code>output_h</code> and <code>output_w</code>. Convention for variable
arrays, e.g. <code>Planes plane[1]</code>, <code>planes</code> and
<code>plane_count (use ARRAY_COUNT macro here)</code> Put for loop
statements on separate line to help not be afraid of indentation.
Iterate over pixel space and then convert to say, world space for
calculations (normalisation and lerp) Aspect ratio correction is simply
rearranging a ratio. If we determine one side is larger, scale other.
Use “ ASCII code to print a status indicator. Only use const for char *
string literals stored in the data segment.</p>
<p>Endianness comes into play when reading/writing from disk (e.g. file
type magic value) and working directly with <code>u8 *</code>
(e.g. iterating through bytes of a u32)</p>
<p>MARKETING APP: f5bot.com,
https://github.com/lawxls/HackerNews-personalized I’m notified when
keywords related to “human wants thing, my app can do thing” appear on
HN, Reddit and Lobsters. If I can then contribute with information to
that discussion, I’ll also leave a link to my app. Don’t just self plug,
people (myself included) appreciate more detailed information on how
they can solve their own personal problem, instead of being thrown into
“here’s an app, figure it out”</p>
<p>even parity is to make it even, i.e. so if 5 1’s, even parity will
add a 1</p>
</body>
</html>
